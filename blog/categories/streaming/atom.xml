<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Streaming | Tech Notes]]></title>
  <link href="http://ogibayashi.github.io/blog/categories/streaming/atom.xml" rel="self"/>
  <link href="http://ogibayashi.github.io/"/>
  <updated>2016-10-21T06:48:32+09:00</updated>
  <id>http://ogibayashi.github.io/</id>
  <author>
    <name><![CDATA[OGIBAYASHI Hironori]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Realtime Data Processing at Facebookを読んで]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/07/12/realtime-data-processing-at-facebook/"/>
    <updated>2016-07-12T23:16:10+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/07/12/realtime-data-processing-at-facebook</id>
    <content type="html"><![CDATA[<p>てすと</p>

<p><a href="https://research.facebook.com/publications/realtime-data-processing-at-facebook/">https://research.facebook.com/publications/realtime-data-processing-at-facebook/</a> を読んだのでなんとなくまとめつつ思ったことなどを書いてみる.
原文のまとめというよりは、主観と自分の理解の記述を多めにしているので、興味を持った人は是非原文を読むことをお勧めします.</p>

<h2>この文章は何か</h2>

<p>Facebookでストリーム処理を運用してきた経験を元に、ストリーム処理として重要な要件、設計上のポイント、Facebookで実際にどうしているか、と言ったことが書いてある. 個人的には、ストリーム処理というものを、製品の比較とかではなくてその機能/非機能面から紐解いてる感じで参考になった.</p>

<h2>ストリーム処理で考慮すべき要件</h2>

<p>ストリーム処理の要件を定義する上では以下が重要</p>

<ul>
<li>Ease of use

<ul>
<li>どれくらい複雑なことをやりたいか. SQLレベルか、プログラムが必要なレベルか.</li>
</ul>
</li>
<li>Performance

<ul>
<li>要求されるレイテンシとスループット</li>
</ul>
</li>
<li>Fault-tolerance

<ul>
<li>対障害性はどの程度必要か？障害時のデータ重複や欠損は許容されるか</li>
</ul>
</li>
<li>Scalability

<ul>
<li>データ流量の変化にどれだけ柔軟に対応できるか</li>
</ul>
</li>
<li>Correctness

<ul>
<li>ACIDが必要？ 入力されたデータは全て確実に出力に反映されている必要があるか</li>
</ul>
</li>
</ul>


<p>例えば、カジュアルなストリーム処理の例としてfluentd+Norikraを考えてみる. これはとても簡単に使えるし、10,000msg/sec程度なら大体問題なく処理できるけど、それ以上にスケールしたいとか、障害時含めてデータの欠損・重複は許さんとか言われると、それは違うソリューションを持ってこないと無理だよね、となる. なので、この辺の観点から要件を明確にするのは重要、と思う.</p>

<h2>Facebookのシステム</h2>

<p>大きく分けると、メッセージバス、ストリーム処理、データストアの3機能になる.</p>

<ul>
<li>メッセージバス

<ul>
<li>scribe. scribeってfluentd的な感じでログを転送・集約してるのかと思ったら、やってることはKafkaらしい. クライアントは自由にcategory(Kafkaで言うtopic)をsubscribeできるし、データは永続化されていてリプレイもできる</li>
</ul>
</li>
<li>ストリーム処理

<ul>
<li>Puma, Stylus, Swiftと3つある.</li>
<li>PumaはSQLで簡単に使える、Swiftはscribeのストリームのここまで読んだよ、というチェックポイント機能を提供する、Stylusは高機能で色々できるけど、C++でコードを書くので処理の記述はちょっと大変、と理解した. Swiftがちょっとよくわからない.</li>
</ul>
</li>
<li>データストア

<ul>
<li>Laser, Scuba, Hiveの3つ</li>
<li>Laserはストリーム処理からも使える高スループットKVS. RocksDBベース.</li>
<li>Scubaはアドホッククエリ用のCube.</li>
<li>Hiveはとにかく全てのデータが入っているDWH. クエリにはPrestoが使える</li>
</ul>
</li>
</ul>


<p>lessons learnedの章にもあるけど、ストリーム処理に複数のプロダクトがあるというのは結構重要で、Pumaでカジュアルに始めつつ、効果が出そうでもっと色々やりたくなったらStylusを使う、というようなことができる.
ストリーム処理とデータストアの関連で言うと、Laserは高スループットをさばけるのでストリーム処理中で使ったり、ストリーム処理の出力を入れたりする、Scubaはストリーム処理で加工した結果を入れる、という感じらしい.</p>

<h2>Design Desicions</h2>

<p>ここが、この文章で最も重要なところ. ストリーム処理を設計する上でのポイント、そしてFacebookではどのような選択をしたか、が書かれている. どれも正解があるわけではなく、複数の選択肢から要件に合わせて選ぶ、という性質のもの.</p>

<ul>
<li>Language paradigm

<ul>
<li>ストリーム処理を書くための言語を何にするか. SQLは簡単だが表現力に劣る、一方で手続き型でがっつりコードを書けるようにすると自由度は高いが開発コストがかかる.</li>
<li>Facebookでは、要件に合わせてストリーム処理エンジンを選べるようになっている.</li>
</ul>
</li>
<li>Data transfer

<ul>
<li>ストリーム処理は大抵複数のオペレータから構成されるが、その間のデータ転送をどうするか.</li>
<li>直接RPCで繋ぐのは性能的に有利だが、信頼性や柔軟性には課題がある. 間にストレージを挟むのはその反対で、信頼性は高く、また送信側・受信側に処理性能の違いがあるケースに間のストレージで吸収できるというメリットがある.</li>
<li>Facebookでは間にscribeを挟む形にしている</li>
</ul>
</li>
<li>Processing semantics

<ul>
<li>障害が発生した際のログ欠損、重複に対してどういうポリシーで行くか. at-least-once, at-most-once, exactly-onceのどれかとなる.</li>
<li>statefulな処理の場合は、stateに対するsemanticsと、outputに対するsemanticsがある. statelessの場合は後者しかない</li>
<li>stateで考えると、どのsemanticsにするかは、状態の保存と読み込んでいるログのオフセット保存をどの順番で行うか、もしくはatomicに行うか、で決まる. 例えば、状態保存→オフセット保存、の場合はログの重複が発生しうるのでat-least-onceになる</li>
</ul>
</li>
<li>State saving mechanisms

<ul>
<li>処理の内部状態をどう保持するか. 耐障害性を考慮すると、障害時に復旧できる形で状態を保持する必要がある. 内部状態を常に他ノードにレプリケートしておくとか、外部のDBに保存するとか、いくつか方法が考えられる</li>
<li>Facebookで良く使われているのは、各サーバ内のDBに保存しつつ、定期的に外部データストアにもバックアップを取る、という方式. local DBに持っておけばプロセス障害などには対応できるし、最悪サーバが返ってこないケースには外部データストアのバックアップを使うことができる.</li>
<li>複数の処理ノード間での状態の整合性、というのに対しては言及がないが、Data transferのところであった通り、Facebookでは多段になっている処理の場合、間にはscribeが入っていて、各処理はscribeのオフセットを管理しているので不整合は発生しない、ということなんだろうか.</li>
</ul>
</li>
<li>Backfill Processing

<ul>
<li>過去データに対して処理を行いたい時にどうするか.</li>
<li>ストリーム処理だけでやろうとすると、過去データを全てストリームとして流せないといけないことになる. かと行って、同じ処理をバッチ用とストリーム用で二重開発するのはコストが高い.</li>
<li>Facebookは、PumaのプログラムをHive上のUDFとして再利用できるようになっている</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>

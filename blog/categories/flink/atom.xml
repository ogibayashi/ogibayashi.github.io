<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Flink | Tech Notes]]></title>
  <link href="http://ogibayashi.github.io/blog/categories/flink/atom.xml" rel="self"/>
  <link href="http://ogibayashi.github.io/"/>
  <updated>2016-04-05T11:26:55+09:00</updated>
  <id>http://ogibayashi.github.io/</id>
  <author>
    <name><![CDATA[OGIBAYASHI Hironori]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Flinkの性能 - デフォルトのJSONパーサが遅かった話]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/04/05/apache-flink-performance/"/>
    <updated>2016-04-05T10:50:12+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/04/05/apache-flink-performance</id>
    <content type="html"><![CDATA[<p>軽くApache Flinkの性能を測ってみた. 構成としては、Fluentd(in_tail→out_kafka_buffered)→Kafka→Flink→Elasticsearchで、仮想アクセスログ的なものに対して、URIごとの件数を1分ごとに集計して出力する、というもの。
メッセージフォーマットはJSON。</p>

<p>```scala</p>

<pre><code>val env = StreamExecutionEnvironment.getExecutionEnvironment
env.enableCheckpointing(1000)
</code></pre>

<p>// &hellip;.</p>

<pre><code>val stream = env
  .addSource(new FlinkKafkaConsumer09[String]("kafka.dummy", new SimpleStringSchema(), properties))
  .map{ json =&gt; JSON.parseFull(json).get.asInstanceOf[Map[String, AnyRef]] }
  .map{ x =&gt; x.get("uri") match {
    case Some(y) =&gt; (y.asInstanceOf[String],1)
    case None =&gt; ("", 1)
  }}
  .keyBy(0)
  .timeWindow(Time.of(1, TimeUnit.MINUTES))
  .sum(1)
  .map{ x =&gt; (System.currentTimeMillis(), x)}
  .addSink(new ElasticsearchSink(config, transports, new IndexRequestBuilder[Tuple2[Long, Tuple2[String, Int]]]  {
    override def createIndexRequest(element: Tuple2[Long, Tuple2[String, Int]], ctx: RuntimeContext): IndexRequest = {
      val json = new HashMap[String, AnyRef]
      json.put("@timestamp", new Timestamp(element._1))
      json.put("uri", element._2._1)
      json.put("count", element._2._2: java.lang.Integer)
      println("SENDING: " + element)
      Requests.indexRequest.index("dummy2").`type`("my-type").source(json)
    }
  }))
</code></pre>

<p>```</p>

<p>環境は以下の通り</p>

<ul>
<li>Kafka : 8vCPU, 8GBMemoryのVM*3, HDP2.4 (Kafka-0.9)

<ul>
<li>パーティション数は1なので、実質broker1台</li>
</ul>
</li>
<li>Flink : JobManager, TaskManagerともに8vCPU, 8GBMemoryのVM (Flink-1.0.0)

<ul>
<li>TaskManagerは3台だが、ジョブ並列度を1にしたので1台でしか動かない状態</li>
</ul>
</li>
<li>Elasticsearch: 4CPU, 4GB MemoryのVM*1 (Elasticsearch 1.7.2)</li>
</ul>


<p>URIは9種類なので、Elasticsearchには毎分9レコードが出力されることにいなる。 Elasticsearchに出力されたURIごとの件数を1分単位に合計したものを、Flinkのスループットと考える。 レコードの生成には <a href="https://github.com/sonots/dummer">dummer</a>を使用した。</p>

<p>で、普通にやったら2,000msg/secの入力を与えて、89,000msg/min = 1,483msg/secしか処理できなかった。FlinkプロセスのCPUが100%(1CPU使いきり)となり、Kafkaのlagが増えていく状態。
チェックポイント外したりESへの出力をやめたりしてみたのだけど、性能はさほど変わらず。</p>

<p>何にCPUを食っているんだろう？と思って、Flinkプロセスのjstackを何回か取ってみたら、こんな感じでJSONのパースを実行中であるケースが殆んどだった。</p>

<p>```</p>

<pre><code>    at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:881)
    at scala.util.parsing.json.JSON$.parseRaw(JSON.scala:51)
    at scala.util.parsing.json.JSON$.parseFull(JSON.scala:65)
    at KafkaTest3$$anonfun$1.apply(KafkaTest3.scala:46)
    at KafkaTest3$$anonfun$1.apply(KafkaTest3.scala:46)
    at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:485)
</code></pre>

<p>```</p>

<p>ということで、パーサをJacksonにしてみた。</p>

<p>```scala
  val mapper = new ObjectMapper()</p>

<p>  def main(args: Array[String]) {</p>

<pre><code>val env = StreamExecutionEnvironment.getExecutionEnvironment
env.enableCheckpointing(1000)

// ...

val stream = env
 .addSource(new FlinkKafkaConsumer09[String]("kafka.json", new SimpleStringSchema(), properties))
  .map(parseJson(_))
  .map{ x=&gt; (x.get("uri").asInstanceOf[String], 1)}
  .keyBy(0)
  .timeWindow(Time.of(1, TimeUnit.MINUTES))
  .sum(1)
  .map{ x =&gt; (System.currentTimeMillis(), x)}
  .addSink(new ElasticsearchSink(config, transports, new IndexRequestBuilder[Tuple2[Long, Tuple2[String, Int]]]  {
    override def createIndexRequest(element: Tuple2[Long, Tuple2[String, Int]], ctx: RuntimeContext): IndexRequest = {
      val json = new HashMap[String, AnyRef]
      json.put("@timestamp", new Timestamp(element._1))
      json.put("uri", element._2._1)
      json.put("count", element._2._2: java.lang.Integer)
      Requests.indexRequest.index("dummy2").`type`("my-type").source(json)
    }
  }))

env.execute("KafkaTest9")
</code></pre>

<p>  }</p>

<p>  def parseJson(x: String): Map[String,AnyRef] = {</p>

<pre><code>mapper.readValue(x,classOf[Map[String,AnyRef]])
</code></pre>

<p>  }</p>

<p>```</p>

<p>そうしたら、スループットが大幅に向上して900,000msg/min=15,000msg/secを20%程度のCPU(1CPUの5分の1)で処理できた。</p>

<p><a href="http://www.slideshare.net/nestorhp/scala-json-features-and-performance">http://www.slideshare.net/nestorhp/scala-json-features-and-performance</a> にScalaで使えるJSONライブラリを比較したスライドがあるのだけど、
これを見るとScala標準のパーサと、その他のライブラリで速度が3桁くらい違う。えーーー、、、</p>

<p>ともあれ、十分に実用的な性能が出そうであることがわかったので良かった。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Flinkを試している]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/02/26/trying-apache-flink/"/>
    <updated>2016-02-26T20:38:01+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/02/26/trying-apache-flink</id>
    <content type="html"><![CDATA[<p>耐障害性と拡張性のあるストリーム処理基盤が欲しい、と思って<a href="https://flink.apache.org/">Apache Flink</a>を調べている. 今はリアルタイム集計に<a href="http://norikra.github.io/">Norikra</a>を使っていて、これはとてもカジュアルに使えて良いのだけど、以下の様なケースだと難しい。</p>

<ul>
<li>比較的止めたくない処理で、サーバ障害時にも自動的に回復して欲しい</li>
<li>1日とか長いtime windowの集計をしているので、途中でサーバが落ちて集計中の状態が失われると辛い</li>
<li>トラフィックが増えてきて、複数サーバに負荷を分散したい</li>
<li>例えばストリームに含まれているIDに対応する値を外部のテーブルから取ってくるような、ちょっと複雑な処理をしたい</li>
</ul>


<h3>Flinkとはどのようなソフトウェアか</h3>

<p>一言で言うと、対障害性と拡張性を備えた、分散ストリーム処理基盤。バッチ処理もストリーム処理の仕組みでできるよね、ということでバッチ用、ストリーム用両方のAPIが提供されている。実行環境としては、Hadoop等と同じようにワーカプロセスが複数のサーバで立ち上がっていて、そこに対してジョブを投げるような感じになっている。バッチではジョブを投げるとデータを処理して終了、だけど、ストリーム処理では投げたジョブはずっと生きていて、ストリームにデータが流れてくるたびにそのデータを処理して出力する、という形になる。ジョブは、JavaとScalaで書くことができる。ロードマップにはSQL的なものもあるっぽいけど、今は存在しない。</p>

<h3>SparkとかStormと何が違うの？</h3>

<p>ググると色々出てくるが、<a href="https://yahooeng.tumblr.com/post/135321837876/benchmarking-streaming-computation-engines-at">米Yahooのベンチマーク</a>とか、<a href="http://www.altaterra.net/blogpost/288668/225612/Which-Stream-Processing-Engine-Storm-Spark-Samza-or-Flink">このページ</a>が分かりやすかった。</p>

<p>Stromとの比較で言うと、処理形態はほぼ同じ。ただ、大きな違いとしてStormでは各処理オペレータはstatelessになっていて、落ちると状態が失われる。永続化したかったら、自分で外部ストレージを使うようなコードを書く必要がある。耐障害性ということろだと、各レコードに対して処理が完了した際にackを返す仕組みがあるので、障害などでackが無かったら再度処理する、というような処理を書く感じになる。なので、例えば処理が途中まで行われて障害になると、そのレコードは重複して処理される形になる。Flinkは<a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html">ここ</a>に詳しく書いてあるけど、オペレータがstatefulになっていて、チェックポイントごとに状態が保存される。障害時には、チェックポイントから復旧し、それ以降のレコードをリプレイすることで、exactly-onceを実現している。</p>

<p>あとは、Stormだと各処理オペレータ(Bolt)をJavaのクラスとして書かないといけないけど、Flinkは<code>stream.keyBy(...).map{...}.timeWindow(...)</code>みたいな感じのハイレベルのAPIが提供されている。</p>

<p>Spark Streamingとの違いで言うと、Spark Streamingは正確にはストリーミングではなくてマイクロバッチなので、そのバッチの間隔にストリーム処理のwindowが左右される。sliding time windowとか、一定数のレコードを保持するようなwindowは作ることができない。(ちゃんとドキュメント読んでないけど、そのはず)</p>

<h3>触ってみた</h3>

<p>とりあえず触ってみるには、<a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/quickstart/setup_quickstart.html">https://ci.apache.org/projects/flink/flink-docs-release-0.10/quickstart/setup_quickstart.html</a> に従えば良い。</p>

<p>ざっくりした流れとしては、</p>

<ul>
<li>バイナリをダウンロードして展開</li>
<li><code>./bin/start-local.sh</code> 実行</li>
<li><a href="http://localhost:8081/">http://localhost:8081/</a> でJobManagerを開く</li>
<li>exampleがバイナリと一緒に配布されているので、それを実行</li>
</ul>


<p>という感じで試すことができる。</p>

<p>クラスタを組むのも割と簡単で、 <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/setup/cluster_setup.html">https://ci.apache.org/projects/flink/flink-docs-release-0.10/setup/cluster_setup.html</a> に従えばできる。</p>

<p>JobManagerというのがマスタで、TaskManagerというのがワーカになっているので、これをサーバに分散配置することになる。</p>

<p>流れとしては、</p>

<ul>
<li>各サーバにflink用のユーザとssh keyを用意

<ul>
<li>ssh keyは、起動スクリプトの中でssh経由でTaskManagerを起動するので必要.自分で各サーバのTaskManagerを起動して回るなら無くても良い</li>
</ul>
</li>
<li>各サーバにバイナリを配布</li>
<li>設定ファイル(flink-conf.yaml, slaves)を用意

<ul>
<li>flink-conf.yamlは、配布されているものをそのまま使って、JobManagerのアドレスを設定すれば良い</li>
<li>slavesはTaskManagerホストを列挙したもの。クラスタ起動スクリプトの中で使われる</li>
</ul>
</li>
</ul>


<p>となる。
  ジョブを書くには、<a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/quickstart/scala_api_quickstart.html">https://ci.apache.org/projects/flink/flink-docs-release-0.10/quickstart/scala_api_quickstart.html</a> に従う。mavenのアーキタイプが用意されてるので、それでプロジェクトのテンプレートを作って、ドキュメントの中にあるWordCountをコピーして走らせれば良い。</p>

<h3>感想</h3>

<p>試しにfluend→Kafka→Flink→Elasticsearch、とつなげて分散実行してみたり、プロセスを落としてみたりしたが、期待通りに動作した。例えば、5分間のtime windowで件数を集計するような処理を作って、実行中にプロセスを落とすと、障害が検知されてジョブが再実行される。そして、勝手に必要なリカバリがされるので、障害があっても無くても実行結果は変わらない。すごい。(もう少しちゃんと見ると、ずれるケースもありそうだけど、まだ詳しく見ていない)</p>

<p>並列度は、ジョブの投入時に指定できるので、ちゃんとKafkaのパーティションを複数作って並列度を指定して実行すれば、各TaskManagerに分散して実行される。</p>

<p>ただ、性能のところが今一つで、処理を3サーバに分散、5,000msg/secを投入してやってみたら、各サーバ1CPUを100%使って、Kafkaにメッセージが滞留する状態になった。実際に処理できたのは4,300msg/secくらい。3CPUで4,300msg/secだと大分コストが高いなあ、という印象。まあ、とりあえず動かしてみただけなので、何か正しくない可能性はある。もう少し試してみたい。</p>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Flink | Tech Notes]]></title>
  <link href="http://ogibayashi.github.io/blog/categories/flink/atom.xml" rel="self"/>
  <link href="http://ogibayashi.github.io/"/>
  <updated>2016-10-27T22:25:10+09:00</updated>
  <id>http://ogibayashi.github.io/</id>
  <author>
    <name><![CDATA[OGIBAYASHI Hironori]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[現在稼働しているFlinkクラスタについて]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/10/21/about-my-flink-deployment/"/>
    <updated>2016-10-21T22:35:50+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/10/21/about-my-flink-deployment</id>
    <content type="html"><![CDATA[<p>先日の<a href="http://www.slideshare.net/linecorp/b-6-new-stream-processing-platformwith-apache-flink">発表</a>で、Apache Flinkを導入するに至った経緯を話したのだけど、具体的な構成とかには触れられなかったので書いておく。</p>

<h2>クラスタの構成について</h2>

<p>今運用してるFlinkクラスタは２つ。サービスで使うためのデータを生成しているものと、社内のレポーティングやモニタリングで使っているもの。前者の方は安定性重視、後者は割とカジュアルにジョブを追加したり、構成を弄ったりできるもの、という感じになっている.</p>

<p>Flinkとしては、クラスタのデプロイメント方式として、独立したdaemonとして動かす方法と、YARNの上で動かす方法があるのだけど、前者の方法にしている. その方が運用上もわかりやすいし、レイヤが少ない分トラブルも少ないだろう、というのが理由.</p>

<p>どちらも物理サーバで、TaskManagerサーバは前者が3台、後者が10台になっている. Flinkのバージョンはそれぞれ1.0.3と1.1.1. JobManagerはもちろんHAで、Flinkが使うHDFSやZookeeperは既存Hadoopクラスタを共用している.</p>

<h2>周辺の構成</h2>

<p>Flinkへのインプットはfluentdで集めたログをKafkaに投入したもの。もともとログはがっつりfluentdで集めてたので、Kafkaを導入して、そちらにも飛ばすようにした。ちなみに、fluentd→kafkaの部分について、導入当初はfluent-plugin-kafkaが使っていたposeidon gemがメンテナンス停止を宣言したりしてて若干不安があったけど、その後poseidonはruby-kafkaに置き換えられ、pluginもfluentdの公式になったりして、安心感が大分増した。開発者の方々には感謝してます。</p>

<p>アウトプットはRedis, Elasticsearch, Kafkaの3パターンがある. 汎用的に使いやすいのはElasticserachで、Kibanaで見たり、集計結果をAPIサーバ経由で他に提供したりしている. Redisは最新の情報にしか興味がなくて、かつ更新頻度が高い場合に使っている. 特定のキーの値を10秒間隔でアップデート、とか. Kafkaは、集計結果を他と連携したいケース. 今は、<a href="https://github.com/ogibayashi/kafka-topic-exporter">kafka-topic-exporter</a> 経由で集計結果を<a href="https://prometheus.io/">Prometheus</a>に入れ、<a href="http://grafana.org/">Grafana</a>で見るために使っている.</p>

<h2>運用周り</h2>

<p>モニタリングは基本的にPrometheus. <a href="https://github.com/matsumana/flink_exporter">flink-exporter</a>と<a href="https://github.com/prometheus/jmx_exporter">jmx-expoter</a>を使ってメトリクスをPrometheusに送り、Grafanaで見ている.</p>

<p>Flinkのメトリクスについては <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/metrics.html">https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/metrics.html</a> に記載があるが、JMXで見るためには、flink-conf.yamlに以下の設定を追加する. なお、これが使えるのはFlink 1.1以降.</p>

<p><code>
metrics.reporters: jmx_reporter
metrics.reporter.jmx_reporter.class: org.apache.flink.metrics.jmx.JMXReporter
env.java.opts: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=5560
</code></p>

<p>jmx_expoterの設定は、<a href="https://gist.github.com/ogibayashi/26c976442592b285fd0ff6b07b08ec60">こんな感じ</a> のものを使っている</p>

<p>すると、こんな感じでFlinkのKafkaConsumerのlagやconsumeされているレコード数を見ることができる.</p>

<p><img src="/images/2016/grafana_flink_kafka.png" alt="Flink_Grafana_Kafka" /></p>

<p>以下は、あるジョブのチェックポイントのサイズ. 長期のスパンで見ると、チェックポイントサイズが増加傾向なので何かしら不要なstateがpurgeされずに溜まっていることが疑われる</p>

<p><img src="/images/2016/grafana_flink_checkpoint.png" alt="Flink_Grafana_Checkpoint" /></p>

<p>監視は外部からdaemonのTCPポートが空いていることを確認している. JobManagerはWebUIポート(8081)を見れば良いが、TaskManagerのポートは起動するたびに変わるので、以下のような設定を入れて固定している.</p>

<p><code>
taskmanager.rpc.port: 6122
taskmanager.data.port: 6121
</code></p>

<p>Flink的なメトリクスとしては、Exceptionの発生数とか、ジョブが失敗や再起動状態にあるジョブの数とかも使ってアラートを上げた方がいいんだろうなぁ、と思いつつまだやっていない</p>

<h2>まとめ</h2>

<p>今productionで動かしているFlinkクラスタについて、構成や運用周りを紹介してみた. これからFlinkを使ってみよう、という人の参考になれば幸いです.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Flinkを試してみての感想]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/05/13/thoughts-on-apache-flink/"/>
    <updated>2016-05-13T19:42:13+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/05/13/thoughts-on-apache-flink</id>
    <content type="html"><![CDATA[<p>しばらくApache Flinkを試してみたので、感想を書いておこうと思う.</p>

<h2>試したこと</h2>

<ul>
<li>standalone modeでのクラスタ構築</li>
<li>ストリーミングジョブを書いてみる

<ul>
<li>TumblingTimeWindowやSlidingTimeWindowでの集計</li>
<li>Kafka SourceとElasticsearch Sinkの利用</li>
<li>必要だったので、カスタムトリガは書いた</li>
</ul>
</li>
<li>幾つかのジョブで性能測定</li>
<li>社内の本番fluentdからKafka経由でFlinkにストリームを投入し、ジョブを十数日くらい連続稼働してみる</li>
<li>state backendをHDFSやRocksDBにしてみる</li>
<li>JobManager HA</li>
<li>TaskManagerやJobManagerを落としてみる</li>
<li>Flink on YARN (ジョブを起動してみただけ)</li>
</ul>


<h2>試してないこと</h2>

<ul>
<li>DataSet APIの利用</li>
<li>savepoint, savepointからの復旧</li>
<li>event timeやingenstion timeの利用(processing timeしか使ってない)</li>
<li>複数ジョブの相乗り</li>
<li>高トラフィックかつ複数ジョブでの連続稼働</li>
<li>Flink on YARNをもうちょっと色々使ってみる</li>
<li>(多分他にも色々)</li>
</ul>


<h2>所感</h2>

<p>全体としてはすごく良く出来ていると思う. プロセスが落ちたりしても勝手に復旧するし、性能も出るし、WebUIやREST APIで色々情報取れるので運用もしやすそう. 今後は本番に入れていこうと思っている.</p>

<ul>
<li>ちゃんと動く？

<ul>
<li>期待通りに動かなくて、MLで聞いたらBugだ、って言われて直してくれたのが2件</li>
<li>ContinuousProcessingTimeTriggerは期待通りの動作をしなかったので、修正版を書く必要があった</li>
<li>後は、上記の範囲では特に問題なく動いている</li>
</ul>
</li>
<li>処理の書きやすさ

<ul>
<li>APIがハイレベルなので、割と少ないコードで処理を書くことができて良い</li>
<li>状態の保存とか、windowとか、自分で書くのは大変なのでその辺の面倒はFlinkが見てくれる</li>
</ul>
</li>
<li>性能

<ul>
<li>もちろん処理によるが、単純なものであれば1CPUで10万records/sec以上は普通に処理できそう</li>
</ul>
</li>
<li>耐障害性

<ul>
<li>ジョブ実行中にJobManagerやTaskManagerを落としてみたが、勝手に復旧された. すごい.</li>
<li>HDFS障害でどう振る舞うか？はまだ試せてないけど気になるところ</li>
</ul>
</li>
<li>運用

<ul>
<li>WebUIやREST APIで色々取れる. WebUIで大抵のものは見える印象.</li>
<li>スロット数とかはもちろん、ジョブ内のオペレータ単位で処理レコード数とか取れる</li>
<li>チェックポイントの所要時間やサイズも取れる</li>
</ul>
</li>
<li>不安なところ

<ul>
<li>チェックポイントのサイズには注意がいりそう. FsStateBackendの場合、状態は全て各TaskManagerのメモリに持ち、チェックポイントでHDFSに書き出される. 差分スナップショット的なものはないので、状態が大きくなってくるとスナップショットに時間がかかり、性能劣化する. キー(keyByで指定する奴)の数が大きいケースでは、RocksDBを使うことで改善されるらしいが、まだそれが有効なケースに出会ってない.</li>
<li>FlinkジョブをYARNで動かす場合を除いて、各TaskManagerは1プロセスで、その中で複数ジョブがスレッドとして動く形になっているのでisolationの部分は不安. あるジョブに引きづられてTaskManagerが固まるとかありそう.</li>
<li>ストリーム処理のプロダクトはいくつかあるし、Facebook, Twitter, Likedinみたいな大御所がバックにいるわけではないので、生き残っていくのだろうか</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>ということで、自分がしばらく試しての所感を書いてみた.
実績の少ないプロダクトという意味での不安感はあるけど、性能、拡張性、耐障害性、APIの使いやすさは素晴らしいと思うので、使っていきたい. これ以上は使ってみないとわからないと思うし. あと、Flink on YARNの場合はYARNが動くクラスタがあれば、別途サーバを用意しなくてもFlinkジョブを動かすことができるので、既にHadoop環境がある場合なんかは、とりあえず試してみると良いんじゃないかと思う.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Flinkのstate管理について]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/04/08/flink-state-management/"/>
    <updated>2016-04-08T12:09:26+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/04/08/flink-state-management</id>
    <content type="html"><![CDATA[<h2>はじめに</h2>

<p>ストリーム処理の中で、処理をstatefulにしたい、という要求はよくある。例えば、1時間のtime windowで件数を集計している場合、ストリームが流れるにつれて内部で保持しているカウンタは増加していく.
そして、障害等で再起動をした時とかには、そのカウンタの値も一緒に復旧したい.</p>

<h2>Flinkにおけるstateの保存</h2>

<p>これに対して、Apache Flinkは定期的に処理状態のスナップショットを取得する、という方法で対応している.
そして、分散環境でまともに全てのスナップショットを取るのは辛いので、分散してスナップショットを取るようにしている. 具体的には<a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html">ここ</a> に詳しいが、ストリームのソースから定期的にBarrierと呼ばれる印を流して、各オペレータはこれを受け取るとスナップショットを保存するようになっている. こうすることで、処理全体を止めずに一貫性のあるスナップショットを取れるよね、という話. 障害時にはスナップショットから状態を復旧し、スナップショット以降のログをリプレイすることで処理を継続する.</p>

<p>スナップショットの保存先は、以下から選択することができる. グローバルのデフォルトを設定することも、ジョブ単位でそれを上書きすることも可能.  (詳しくは<a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/state_backends.html">ここ</a>)</p>

<ul>
<li>MemoryStateBacked

<ul>
<li>デフォルト. チェックポイントの際にJobManagerのメモリ上に状態を保持する. デフォルトはサイズが5MBまで.</li>
</ul>
</li>
<li>FsStateBackend

<ul>
<li>ファイルシステムに保持する. 最新の状態はTaskManagerのメモリに保持し、チェックポイントの際にファイルシステムに保存する. ファイルシステムはローカルでもHDFSでも良いが、障害時に別ノードで復旧することを考えるとHDFSになるだろう.</li>
</ul>
</li>
<li>RocksDBStateBackend

<ul>
<li>最新の状態はTaskManagerローカルファイルシステム上のRocksDBに保持し、チェックポイントの際にそれをFsStateBackendと同じようにファイルシステムに保存する. スループットは若干落ちるが、大量のstateを保持することができる.</li>
</ul>
</li>
</ul>


<h2>実験</h2>

<p>とは言え、処理によってはstateが大きくなるケースもあるわけで、そういう時にどうなるんだろう？と思って実験してみた.
環境はFlink 1.0.0でKafka, Flink, HDFSは物理サーバ.</p>

<p>こんな感じで、foobarというフィールドに100バイトのランダム文字列を入れて、それのdistinct countを取る. 重複を判断するためには、過去の値をすべて持たないといけないので状態は大きくなる.</p>

<p><code>
$ head -n 1 dummy_log.aa
id:0000 time:[2016-04-05 12:40:57]      level:DEBUG     method:POST     uri:/api/v1/people1     reqtime:3.053540515830725       foobar:dNjtvYKxgyym6bMNxUyrLznijuZqZfpVasJyXZDttoNGbj5GFk
</code></p>

<p>こんな感じのコードで、処理を記述した(MyContinuousProcessingTimeTriggerはデフォルトのContinuousProcessingTimeTriggerに若干の改修を入れたもの).
保存先はHDFSとしている. timeWindowAllなので、処理は分散されず単一のスレッドで処理される.</p>

<p>```scala</p>

<pre><code>val stream = env
  .addSource(new FlinkKafkaConsumer09[String]("kafka.json2", new SimpleStringSchema(), properties))

.map(parseJson(_))
  .timeWindowAll(Time.of(10, TimeUnit.DAYS))
  .trigger(MyContinuousProcessingTimeTrigger.of(Time.seconds(5)))
  .fold(Set[String]()){(r,i) =&gt; { r + i}}
  .map{x =&gt; (System.currentTimeMillis(), x.size)}
  .addSink(new ElasticsearchSink(config, transports, new IndexRequestBuilder[Tuple2[Long, Int]]  {
    override def createIndexRequest(element: Tuple2[Long, Int], ctx: RuntimeContext): IndexRequest = {
      val json = new HashMap[String, AnyRef]
      json.put("@timestamp", new Timestamp(element._1))
      json.put("count", element._2: java.lang.Integer)
      Requests.indexRequest.index("dummy3").`type`("my-type").source(json)
    }
  }))
</code></pre>

<p>```</p>

<p>まずは、260万件のログを送ってスナップショットのサイズを確認してみる. 送信したログのサイズ(100bytes×260万件)とほぼ同じ. そして、同じログを2回投入しても(distinct countなので
)サイズは増えない. 処理内部で集計した結果を保存している模様.</p>

<p><code>
$ cat dummy_log.aa &gt;&gt; /tmp/dummy_log2.log
$ hadoop fs -du  /apps/flink/checkpoints/9005988ca4dc6e871d50c2b310ed0a63
26000230  /apps/flink/checkpoints/9005988ca4dc6e871d50c2b310ed0a63/chk-183
$ cat dummy_log.aa &gt;&gt; /tmp/dummy_log2.log
$ hadoop fs -du  /apps/flink/checkpoints/9005988ca4dc6e871d50c2b310ed0a63
26000230  /apps/flink/checkpoints/9005988ca4dc6e871d50c2b310ed0a63/chk-196
</code></p>

<p>そして、その時のチェックポイント時間はJobManagerのログから確認できる. 大体6秒くらいかかる. TaskManagerのCPU使用率は定常的に高い.</p>

<p><code>
INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator     - Completed checkpoint 43 (in 6291 ms)
</code></p>

<p>さらに、260万件を追加で投入するとチェックポイントに10秒〜数十秒かかるようになった. ジョブを実行しているTaskManagerは
CPU100%になり、スループットも大幅に落ちていた.</p>

<p><code>
INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator     - Completed checkpoint 145 (in 41835 ms)
INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator     - Completed checkpoint 146 (in 13530 ms)
</code></p>

<p><a href="http://mail-archives.apache.org/mod_mbox/flink-user/201604.mbox/%3CCAMvK%3DYpTb6yZiv9ioL7%2Bmdn0W5Q3fRyNL210aGYcjzcbXQWxqg%40mail.gmail.com%3E">MLで聞いてみた</a> ところ、バックエンドでRocksDBを
試してみたら、とアドバイスをもらったのでやってみたが、変わらなかった. この処理の場合、状態を保存するストアには1レコードしか入らなくて、その値が非常に大きいので、効果が出なかった模様.</p>

<h2>思ったことなど</h2>

<ul>
<li>ユニークユーザ数等をカウントするようなケースだと、値の種類が数千万というのもあり得るので、上のような性能だと辛い. そして、このような処理の場合、最終的には一箇所にまとめて
数を数える感じになるので、分散スナップショットの恩恵も受けづらい.</li>
<li>現行のFlinkだと、スナップショットのたびに保持しているデータを全て書き出すので、incremental snapshotが導入されれば改善されるかも.</li>
<li>今の時点での対応としては、値のリストをFlinkに保持せずに外部のデータストア(Redisとか)に保持するというのが一つの解決策. その場合、デメリットとしてはスケールアウトが
制限されることと、障害時などにログがリプレイされることへの対応. ただ、後者については処理の性質上、何度同じデータを投入しても結果は変わらないので、問題にならない.</li>
<li>もしくは、HyperLogLogのような推定アルゴリズムを使って、精度と引き換えに状態のサイズを削減するか.</li>
</ul>


<p>試しにFlinkで受け取った値をRedisのSETに入れて同じ処理を実現してみたら、あっさり1000万件くらい処理できた. stateが小さい、または分散される場合はFlinkに任せて、
今回のような一部のケースでは外部のデータストアを使う、というのが現実的だろうか、と思っているところ.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Flink ContinuousProcessingTimeTriggerの話]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/04/05/apache-flink-continuousprocessingtimetrigger/"/>
    <updated>2016-04-05T11:33:23+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/04/05/apache-flink-continuousprocessingtimetrigger</id>
    <content type="html"><![CDATA[<p>(注: window周りのAPIを変えようという話(<a href="https://issues.apache.org/jira/browse/FLINK-3643">FLINK-3643</a>)があるので、以下で書かれている内容は近い将来obsoleteになる可能性があります)</p>

<p>自分のところでは、ストリーム処理のユースケースとして、ある程度長期間のwindowでデータを保持しながら、集計結果は短い間隔で出力したい、というのがある。</p>

<p>例えば、Norikra(Esper)のクエリだとこんな感じ。site_idごとに、過去3日間(72時間)のユニークユーザを集計し、結果は1分ごとに出力する、というもの。 集計対象のwindowは72時間のsliding time windowとなる。こういうwindowが長いケースは、Norikraだとプロセスを再起動したりした時にwindowの内容が全て失われるので辛い。Flinkでいい感じに実装したい。</p>

<p>```sql
SELECT</p>

<pre><code>site_id,
count(distinct userkey) as num_uu
</code></pre>

<p>FROM</p>

<pre><code>viewer_log.win:time(3 day)
</code></pre>

<p>GROUP BY</p>

<pre><code>site_id
</code></pre>

<p>OUTPUT LAST EVERY 1 min
```</p>

<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.0/apis/streaming/windows.html">ドキュメント</a>を読むと、以下のようにwindowの定義とは別にいつ計算処理がトリガされるか、いつwindowの中身が削除されるか、を好きに設定できるように見える。</p>

<p>```scala
keyedStream</p>

<pre><code>.window(SlidingEventTimeWindows.of(Time.seconds(5), Time.seconds(1))
.trigger(CountTrigger.of(100))
.evictor(CountEvictor.of(10));
</code></pre>

<p>```</p>

<p>なので、上記のようなものは以下の様なコードで実現できるかと思った。ContinuousProcessingTimeTriggerは、指定した間隔で集計を実行するが、その際にwindowの内容の削除は行わない、というもの。</p>

<p>```scala
  def main(args: Array[String]) {
//&hellip;</p>

<pre><code>val input = env.readFileStream(fileName,100,FileMonitoringFunction.WatchType.PROCESS_ONLY_APPENDED)
  .map(lineToTuple(_))
  .keyBy(0)
  .timeWindow(Time.of(3, TimeUnit.DAYS))
  .trigger(ContinuousProcessingTimeTrigger.of(Time.seconds(60)))
  .fold(("",new scala.collection.mutable.HashSet[String]())){(r,i) =&gt; { (i._1, r._2 + i._2)}}
  .map{x =&gt; (new Timestamp(System.currentTimeMillis()), x._1, x._2.size)}
</code></pre>

<p>//&hellip;
  }
  def lineToTuple(line: String) = {</p>

<pre><code>val x = line.split("\\W+") filter {_.nonEmpty}
(x(0),x(1))
</code></pre>

<p>  }</p>

<p>```</p>

<p>が、実際には期待どおりに動かないことが分かった。(MLで教えてもらった。<a href="http://mail-archives.apache.org/mod_mbox/flink-user/201603.mbox/%3CCAMvK=YpGWZZQQnPVknGYY07AhieHE+9ELkq0i6Q_72FCghsm-Q@mail.gmail.com%3E">ここ</a>とか<a href="http://mail-archives.apache.org/mod_mbox/flink-user/201603.mbox/%3CCAMvK%3DYo2NMk3Hxhie5Cr9coHS7qZ8ecaGOHHXg96mDB7H9_7Nw%40mail.gmail.com%3E">ここ</a>)</p>

<ul>
<li>トリガが発火しないケースがある</li>
<li>timeWindowが終了してもwindow内のデータが削除されない。結果、stateのサイズが増加する一方になる。(.trigger()を呼び出した時点で、元のtimeWindowのトリガは上書きされるらしい)</li>
</ul>


<p>って、これContinuousProcessingTimeTriggerは使えないのでは・・・。</p>

<p>結局、ContinuousProcessingTimeTriggerに修正を入れたカスタムTriggerを作成し、これを使用することで期待する動作をするようになった。</p>

<p>```java
@PublicEvolving
public class MyContinuousProcessingTimeTrigger<W extends TimeWindow> extends Trigger&lt;Object, W> {</p>

<pre><code>private static final long serialVersionUID = 1L;

private final long interval;

private final ValueStateDescriptor&lt;Long&gt; stateDesc =
        new ValueStateDescriptor&lt;&gt;("fire-timestamp", LongSerializer.INSTANCE, 0L);


private MyContinuousProcessingTimeTrigger(long interval) {
    this.interval = interval;
}

@Override
public TriggerResult onElement(Object element, long timestamp, W window, TriggerContext ctx) throws Exception {
    long currentTime = System.currentTimeMillis();

    ValueState&lt;Long&gt; fireState = ctx.getPartitionedState(stateDesc);
    long nextFireTimestamp = fireState.value();

    if (nextFireTimestamp == 0) {
        long start = currentTime - (currentTime % interval);
        fireState.update(start + interval);

        ctx.registerProcessingTimeTimer((start + interval));
        return TriggerResult.CONTINUE;
    }
    if (currentTime &gt;= nextFireTimestamp) {
        long start = currentTime - (currentTime % interval);
        fireState.update(start + interval);

        ctx.registerProcessingTimeTimer((start + interval));

        return TriggerResult.FIRE;
    }
    return TriggerResult.CONTINUE;
}

@Override
public TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception {
    return TriggerResult.CONTINUE;
}

@Override
public TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception {

    ValueState&lt;Long&gt; fireState = ctx.getPartitionedState(stateDesc);
    long nextFireTimestamp = fireState.value();

    // only fire if an element didn't already fire
    long currentTime = System.currentTimeMillis();
    if (currentTime &gt;= nextFireTimestamp) {
        long start = currentTime - (currentTime % interval);
                    fireState.update(0L);
                    if (nextFireTimestamp &gt;= window.getEnd()) {
                       return TriggerResult.FIRE_AND_PURGE;
                    }
                    else {
                        return TriggerResult.FIRE;
                    }
            }
    return TriggerResult.CONTINUE;
}

@Override
public void clear(W window, TriggerContext ctx) throws Exception {}

@VisibleForTesting
public long getInterval() {
    return interval;
}

@Override
public String toString() {
    return "ContinuousProcessingTimeTrigger(" + interval + ")";
}

/**
 * Creates a trigger that continuously fires based on the given interval.
 *
 * @param interval The time interval at which to fire.
 * @param &lt;W&gt; The type of {@link Window Windows} on which this trigger can operate.
 */
public static &lt;W extends TimeWindow&gt; MyContinuousProcessingTimeTrigger&lt;W&gt; of(Time interval) {
    return new MyContinuousProcessingTimeTrigger&lt;&gt;(interval.toMilliseconds());
}
</code></pre>

<p>}
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Flinkの性能 - デフォルトのJSONパーサが遅かった話]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/04/05/apache-flink-performance/"/>
    <updated>2016-04-05T10:50:12+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/04/05/apache-flink-performance</id>
    <content type="html"><![CDATA[<p>軽くApache Flinkの性能を測ってみた. 構成としては、Fluentd(in_tail→out_kafka_buffered)→Kafka→Flink→Elasticsearchで、仮想アクセスログ的なものに対して、URIごとの件数を1分ごとに集計して出力する、というもの。
メッセージフォーマットはJSON。</p>

<p>```scala</p>

<pre><code>val env = StreamExecutionEnvironment.getExecutionEnvironment
env.enableCheckpointing(1000)
</code></pre>

<p>// &hellip;.</p>

<pre><code>val stream = env
  .addSource(new FlinkKafkaConsumer09[String]("kafka.dummy", new SimpleStringSchema(), properties))
  .map{ json =&gt; JSON.parseFull(json).get.asInstanceOf[Map[String, AnyRef]] }
  .map{ x =&gt; x.get("uri") match {
    case Some(y) =&gt; (y.asInstanceOf[String],1)
    case None =&gt; ("", 1)
  }}
  .keyBy(0)
  .timeWindow(Time.of(1, TimeUnit.MINUTES))
  .sum(1)
  .map{ x =&gt; (System.currentTimeMillis(), x)}
  .addSink(new ElasticsearchSink(config, transports, new IndexRequestBuilder[Tuple2[Long, Tuple2[String, Int]]]  {
    override def createIndexRequest(element: Tuple2[Long, Tuple2[String, Int]], ctx: RuntimeContext): IndexRequest = {
      val json = new HashMap[String, AnyRef]
      json.put("@timestamp", new Timestamp(element._1))
      json.put("uri", element._2._1)
      json.put("count", element._2._2: java.lang.Integer)
      println("SENDING: " + element)
      Requests.indexRequest.index("dummy2").`type`("my-type").source(json)
    }
  }))
</code></pre>

<p>```</p>

<p>環境は以下の通り</p>

<ul>
<li>Kafka : 8vCPU, 8GBMemoryのVM*3, HDP2.4 (Kafka-0.9)

<ul>
<li>パーティション数は1なので、実質broker1台</li>
</ul>
</li>
<li>Flink : JobManager, TaskManagerともに8vCPU, 8GBMemoryのVM (Flink-1.0.0)

<ul>
<li>TaskManagerは3台だが、ジョブ並列度を1にしたので1台でしか動かない状態</li>
</ul>
</li>
<li>Elasticsearch: 4CPU, 4GB MemoryのVM*1 (Elasticsearch 1.7.2)</li>
</ul>


<p>URIは9種類なので、Elasticsearchには毎分9レコードが出力されることにいなる。 Elasticsearchに出力されたURIごとの件数を1分単位に合計したものを、Flinkのスループットと考える。 レコードの生成には <a href="https://github.com/sonots/dummer">dummer</a>を使用した。</p>

<p>で、普通にやったら2,000msg/secの入力を与えて、89,000msg/min = 1,483msg/secしか処理できなかった。FlinkプロセスのCPUが100%(1CPU使いきり)となり、Kafkaのlagが増えていく状態。
チェックポイント外したりESへの出力をやめたりしてみたのだけど、性能はさほど変わらず。</p>

<p>何にCPUを食っているんだろう？と思って、Flinkプロセスのjstackを何回か取ってみたら、こんな感じでJSONのパースを実行中であるケースが殆んどだった。</p>

<p>```</p>

<pre><code>    at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:881)
    at scala.util.parsing.json.JSON$.parseRaw(JSON.scala:51)
    at scala.util.parsing.json.JSON$.parseFull(JSON.scala:65)
    at KafkaTest3$$anonfun$1.apply(KafkaTest3.scala:46)
    at KafkaTest3$$anonfun$1.apply(KafkaTest3.scala:46)
    at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:485)
</code></pre>

<p>```</p>

<p>ということで、パーサをJacksonにしてみた。</p>

<p>```scala
  val mapper = new ObjectMapper()</p>

<p>  def main(args: Array[String]) {</p>

<pre><code>val env = StreamExecutionEnvironment.getExecutionEnvironment
env.enableCheckpointing(1000)

// ...

val stream = env
 .addSource(new FlinkKafkaConsumer09[String]("kafka.json", new SimpleStringSchema(), properties))
  .map(parseJson(_))
  .map{ x=&gt; (x.get("uri").asInstanceOf[String], 1)}
  .keyBy(0)
  .timeWindow(Time.of(1, TimeUnit.MINUTES))
  .sum(1)
  .map{ x =&gt; (System.currentTimeMillis(), x)}
  .addSink(new ElasticsearchSink(config, transports, new IndexRequestBuilder[Tuple2[Long, Tuple2[String, Int]]]  {
    override def createIndexRequest(element: Tuple2[Long, Tuple2[String, Int]], ctx: RuntimeContext): IndexRequest = {
      val json = new HashMap[String, AnyRef]
      json.put("@timestamp", new Timestamp(element._1))
      json.put("uri", element._2._1)
      json.put("count", element._2._2: java.lang.Integer)
      Requests.indexRequest.index("dummy2").`type`("my-type").source(json)
    }
  }))

env.execute("KafkaTest9")
</code></pre>

<p>  }</p>

<p>  def parseJson(x: String): Map[String,AnyRef] = {</p>

<pre><code>mapper.readValue(x,classOf[Map[String,AnyRef]])
</code></pre>

<p>  }</p>

<p>```</p>

<p>そうしたら、スループットが大幅に向上して900,000msg/min=15,000msg/secを20%程度のCPU(1CPUの5分の1)で処理できた。</p>

<p><a href="http://www.slideshare.net/nestorhp/scala-json-features-and-performance">http://www.slideshare.net/nestorhp/scala-json-features-and-performance</a> にScalaで使えるJSONライブラリを比較したスライドがあるのだけど、
これを見るとScala標準のパーサと、その他のライブラリで速度が3桁くらい違う。えーーー、、、</p>

<p>ともあれ、十分に実用的な性能が出そうであることがわかったので良かった。</p>
]]></content>
  </entry>
  
</feed>

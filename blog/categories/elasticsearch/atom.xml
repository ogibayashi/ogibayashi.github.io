<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Elasticsearch | Tech Notes]]></title>
  <link href="http://ogibayashi.github.io/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://ogibayashi.github.io/"/>
  <updated>2016-11-10T11:55:12+09:00</updated>
  <id>http://ogibayashi.github.io/</id>
  <author>
    <name><![CDATA[OGIBAYASHI Hironori]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[多種多様なログをFluentd-Elasticsearch-Kibanaしたメモ]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/11/09/fluentd-elasticsearch-kibana/"/>
    <updated>2016-11-09T19:36:46+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/11/09/fluentd-elasticsearch-kibana</id>
    <content type="html"><![CDATA[<p>自分のところでは、社内の様々なログをfluentdで集めているのだけど、それらをElasticsearchに入れて、Kibanaで見えるようした話を書いてみる.</p>

<p>Fluentd, Elasticsearch, Kibanaな組み合わせは既に多くの人が使ってるし、ブログ等の記事も沢山ある. けど、いくつか
引っ掛かった点などもあるので、それらを書き留めて置こうと思う.</p>

<h2>要件</h2>

<ul>
<li>fluentdでストリームで集めてるログを、リアルタイムに近い鮮度でKibanaで見たい.

<ul>
<li>見たい、というのは検索したり、集計・可視化したり、ということ</li>
</ul>
</li>
<li>Kibanaでは短期(2日とか)のログが見えれば良い</li>
<li>規模感的には、ログの種類(=fluentdのtag数)が200くらい、流量はピークで2万メッセージ/秒くらい.

<ul>
<li>が、実際には最も流量の多いログは除いたので、この半分〜3分の1くらいの流量</li>
<li>10shard/index にしてあるので、２日分だと4000 shardくらいになる. これはかなり多いと思う</li>
</ul>
</li>
<li>ログの種類が増えたときも、人手をかけずにKibanaで見えるようになって欲しい</li>
</ul>


<h2>構成</h2>

<p>fluentd→Kafka→<a href="https://github.com/treasure-data/kafka-fluentd-consumer">kafka-fluentd-consumer</a>→fluentd→Elasticsearch</p>

<p>な感じ. Elasticsearchへの投入が詰まる、的な話はよくあるけど、Kafkaを挟んでいるのでfluentdの他の経路に影響が出ることは無いようになっている.</p>

<h2>経験した問題と対応</h2>

<h3>fluentdからの投入タイムアウト</h3>

<p>これに出会ったのは大分前なのだけど、流量が多い場合にバッファのサイズが大きくなると、Elasticsearchへの投入でタイムアウトが発生したりした.</p>

<p><code>
2015-09-30 18:02:48 +0900 [warn]: temporarily failed to flush the buffer. next_retry=2015-09-30 18:01:02 +0900 error_class="Fluent::ElasticsearchOutput::ConnectionFailure" error="Could not push logs to Elasticsearch after 2 retries. read timeout reached" plugin_id="object:3fe40898b7d8"
</code></p>

<p>対応として、fluent-plugin-elasticsearchの設定で<code>request_timeout</code>を長めに設定している.</p>

<h3>Size of the emitted data exceeds buffer_chunk_limit</h3>

<p>kafka-fluentd-consumer からログを受けているfluentdで、以下のようなwarningが多発した.</p>

<p><code>
2016-07-31 21:22:51 +0900 [warn]: Size of the emitted data exceeds buffer_chunk_limit.
2016-07-31 21:22:51 +0900 [warn]: This may occur problems in the output plugins ``at this server.``
2016-07-31 21:22:51 +0900 [warn]: To avoid problems, set a smaller number to the buffer_chunk_limit
2016-07-31 21:22:51 +0900 [warn]: in the forward output ``at the log forwarding server.``
</code></p>

<p>fluentdがin_forwardで受け取ったchunkのサイズが、受け側fluentdでのbuffer_chunk_limit(デフォルト8MB)より大きいよ、という
メッセージ.</p>

<p>kafka-fluentd-consumerが大きいchunkで送信していたと思われる. 当時はこれを制御する術は無かったのだけど、issueをあげたら
対応してもらえた. このためにkafka-fluentd-consumerが内部で使っている<a href="https://github.com/komamitsu/fluency">Fluency</a>にも、改修を入れてくれた様子. 有り難い.</p>

<p><a href="https://github.com/treasure-data/kafka-fluentd-consumer/issues/15">https://github.com/treasure-data/kafka-fluentd-consumer/issues/15</a></p>

<p>こんな感じで、Fluencyのバッファ周りのパラメータを指定できるようになったので、<code>fluentd.client.buffer.chunk.retention.bytes</code>がfluentdのbuffer_chunk_limitより小さくなるようにした.
あとは、Elasticsearchに投入するfluentdプロセスの数を多めにして、一つ一つの負荷が大きくならないようにしている.</p>

<p><code>
fluentd.client.buffer.chunk.initial.bytes = 1000000
fluentd.client.buffer.chunk.retention.bytes = 8000000
fluentd.client.buffer.max.bytes = 512000000
</code></p>

<p>実際には、この設定を入れる前の段階で(なぜか)warningが消えていたので、明確にこれの効果があったのかは不明. だけど、その後ログの流量を大分増やしたりしても
出ていないので、多分効果はあったのだろう.</p>

<h3>日付が変わったタイミングでElasticsearchが固まる問題</h3>

<p>時系列データなので、indexは<code>somelog-YYYY.MM.DD</code>のような形で、日毎に分けるようにしている. 一部のログだけを入れていた時は特に問題は無かったのだけど、
全ての(大体200種類の)ログを入れるようにした所、日付が変わった際にElasticsearchへのindexingが固まる、という事象に出会った.</p>

<p><img src="/images/2016/Elasticsearch_indexing_rate.png" alt="Elasticsearch_indexing_rate" /></p>

<p>Elasticsearchのログを見ると、以下のようなログが大量に発生している.</p>

<p><code>
ProcessClusterEventTimeoutException[failed to process cluster event (put-mapping [fluentd]) within 30s]
at org.elasticsearch.cluster.service.InternalClusterService$2$1.run(InternalClusterService.java:349)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
</code></p>

<p>これについては、Elasticsearchのフォーラムで質問をしてみた.
<a href="https://discuss.elastic.co/t/timeout-exception-with-many-time-based-indices-after-00-00/63340/1">https://discuss.elastic.co/t/timeout-exception-with-many-time-based-indices-after-00-00/63340/1</a></p>

<p>mapping等の情報はcluster stateと呼ばれるメタデータで管理されていて、これの更新はシングルスレッドになっている. dynamic mappingを使っている場合、
新規indexの作成時に新たなmappingの作成も発生し、indexの数が多い場合は、これが大量に発生するために固まったような状態になるのだろう、ということ.</p>

<p>対策として、ここで教えてもらったように、翌日分のindexを事前に作成しておくようにした.</p>

<h3>フィールド名にドットが含まれている場合の問題</h3>

<p>色々なログが入って来た結果、フィールド名にドットが含まれているものがあり、以下のようなエラーが発生</p>

<p>```
[2016-11-10 11:30:06,915][DEBUG][action.admin.indices.mapping.put] [ESHOST1] failed to put mappings on indices [[some.log-2016.11.10]], type [fluentd]
MapperParsingException[Field name [somefield.channel] cannot contain &lsquo;.&rsquo;]</p>

<pre><code>    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:277)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:222)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parse(ObjectMapper.java:197)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:309)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:222)
    at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:139)
    at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:118)
    at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:99)
    at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:549)
    at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:257)
    at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
    at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
    at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
</code></pre>

<p>```</p>

<p>ドットを含むフィールド名の扱いはバージョンによって違っていて、1.xでは可能だったが、2.xでは不可になった.
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.0/breaking_20_mapping_changes.html#_field_names_may_not_contain_dots">https://www.elastic.co/guide/en/elasticsearch/reference/2.0/breaking_20_mapping_changes.html#_field_names_may_not_contain_dots</a></p>

<p>その後、2.4以降では起動時のオプションに<code>-Dmapper.allow_dots_in_name=true</code>を付けると、ドットを含むフィールド名も入るようになった.
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.4/dots-in-names.html">https://www.elastic.co/guide/en/elasticsearch/reference/2.4/dots-in-names.html</a></p>

<p>そして、5.0以降では再びドットを含むフィールドがOKになった. 今使っているElasticsearchは2.4.0なので、オプションで解決することもできたが、
開発者がドットを含まない形にログの形式を変更してくれることになった.</p>

<h3>Kibanaでのindex pattern作成が面倒</h3>

<p>kafka-fluentd-consumerは、Kafkaから読み込むtopicを正規表現のパターンで指定することができて、fluentd tag=topicが増えた場合は自動的に追随してくれる.
なので、ログの種類が増えてもElasticsearchまでは自動的に格納される.</p>

<p>が、Kibanaで見るためにはindex patternの設定が必要になる. これを毎回やるのは面倒なので、どうにかしたい.</p>

<p>同じような要望はあって、この操作をAPIでできるようにして欲しい、というissueが存在している. <a href="https://github.com/elastic/kibana/issues/5199">https://github.com/elastic/kibana/issues/5199</a></p>

<p>結構長く存在するissueだが、対応されてKibana5ではできるようになるらしい.</p>

<p>が、Kibana5はつい先日GAが出たばかり. 使っているのはまだKibana4だ. Kibana4では、index patternを始めKibana上で作ったオブジェクトの定義は、.kibanaというindexに格納されているので、
これを自分で作る方針にする.</p>

<p>.kibanaに格納されているindex patternの定義は、例えばこんな感じ.</p>

<p>```
  {</p>

<pre><code>  "_index": ".kibana",
  "_type": "index-pattern",
  "_id": "log.hiveserver2-*",
  "_version": 2,
  "_score": 1,
  "_source": {
      "title": "log.hiveserver2-*",
      "timeFieldName": "@timestamp",
      "fields": "[{"name":"_index","type":"string","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"_source","type":"_source","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"tag_key","type":"string","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"message","type":"string","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"hostname","type":"string","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"@timestamp","type":"date","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"_id","type":"string","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"_type","type":"string","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"_score","type":"number","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false}]"
  }
</code></pre>

<p>  }
```</p>

<p>fieldsの中身がちょっと面倒. 基本的には、既存のindexのmappingを取得し、Kibanaのソースコードを参考にしながら定義を作る.</p>

<p><a href="https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_map_field.js">https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_map_field.js</a>
<a href="https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_cast_mapping_type.js">https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_cast_mapping_type.js</a></p>

<p>例えば、<code>indexed</code>フィールドは、mappingの中の<code>index</code>フィールドが存在しない、または<code>no</code>のときのみ<code>false</code>として、その他の場合は<code>true</code>にする. とか、ElasticsaerchとKibanaでは型が違うので、long→numberみたいに変換する、とか.</p>

<p>これも、日次のバッチで回すようにした</p>

<h2>まとめ</h2>

<ul>
<li>こんな感じで様々なログを、Elasticsearch+Kibanaで見ることができるようになった.</li>
<li>fluentd→Elasticsearchについては、以下の部分がキャパシティ的に問題になりやすい印象

<ul>
<li>fluentd: 流量が多いと普通にCPUが上がって詰まる. 対策として、プロセスを増やして負荷分散する</li>
<li>Elasticsearch: 流量よりは、index数(shard数)が増えることに対して注意がいる. 流量はスケールアウトで対応できるが、cluster state管理の部分はスケールしない. 今回は、日付が切り替わった際の翌日分index作成で問題がおきたので、事前にindexを作成することで対応した. できるだけ、index数は多くなりすぎないように設計した方が良いと思う.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第6回Elasticsearch勉強会]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/09/17/elasticsearch-study-6th/"/>
    <updated>2014-09-17T00:19:06+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/09/17/elasticsearch-study-6th</id>
    <content type="html"><![CDATA[<p>第6回Elasticsearch勉強会に参加したので、記憶が新しいうちにメモ. 内容は資料を見れば分かると思うので、個人的に特に記憶に残ったポイントと、感想のみ.</p>

<h2>Aggregationあれこれ @johtani 氏</h2>

<ul>
<li>ElasticsearchのAggregation機能を使うと、SQLで言う集計 group by 的なものができると、という話</li>
<li>動きとしては、各shard内でaggregateし、最後にその結果を集約する、という形. 普通のqueryと変わらない</li>
<li>クエリの種類によっては、正確な値ではなく近似値だったりする</li>
<li>Field Collapsingという、URLごとにtop Nを検索するようなこともできる</li>
<li>個人的な感想

<ul>
<li>便利な機能なので、是非使いたい. 現状だとKibana3で使えないのがネックだけど、Kibana4だと使えるようになるらしいので期待</li>
</ul>
</li>
</ul>


<h2>秒間3万の広告配信ログをElasticSearchで リアルタイム集計してきた戦いの記録 @satully 氏</h2>

<ul>
<li><a href="http://www.slideshare.net/Satully/elasticsearch-study6threaltime20140916">資料</a></li>
<li>商用での利用事例、という意味ですごく興味深かった</li>
<li>DSPの配信システムで利用. 最大秒間30000ログ. 1.5TB/日くらい</li>
<li>各サーバのログ &ndash;> fluentd &ndash;> Elasticsearch &ndash;> MySQL/Redis という構成</li>
<li>fluentdは10インスタンス</li>
<li>ElasticsearchはCoordinate:2ノード, Search:2ノード, Data:28ノード.全てAWSのr3.largeインスタンス. メモリは30GBくらい？

<ul>
<li>diskは途中でSSDに変えた</li>
<li>CoordinateとSearchを分離する、というのは世間で見かけるけど、実際に負荷をみると必要性が疑問</li>
<li>1日1index, 1index12shard, 1レプリ.</li>
</ul>
</li>
<li>単純なログのinsertのみではなく、Bidと紐付けるべきログが来ると、元のBidのログに項目を追加する. fluentd pluginとして実装</li>
<li>運用ツールとしては、Elasticsearchのpluginとしてhead, bigdesk, ElasticHQ. 死活監視やfluentdのメトリックにはZABBIX</li>
<li>個人的な感想

<ul>
<li>サーバスペック、台数、流量の具体的な事例としてとても参考になった</li>
<li>indexサイズはかなり大きくなるけど、いけるものなんだ.</li>
<li>お金の計算に関わる部分に、fluentdとかElasticsearchとか使っている、というのに驚いた</li>
</ul>
</li>
</ul>


<h2>Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応 @9215 氏</h2>

<ul>
<li><a href="https://speakerdeck.com/kunihikokido/elasticsearch-ri-ben-yu-sukimaresuhuan-jing-gou-zhu-to-tuideniduo-yan-yu-dui-ying">資料</a></li>
<li>スキーマをちゃんと設計して、それに合わせてマッピング定義するのは面倒. どんなフィールドでどんなマッピングが最適、とか個別に設計すると人材がスケールしない.</li>
<li>そこで、dynamic templateとindex templateを使い、ノウハウが必要な部分はtemplateに集約、各利用者(データを投入する人)にはフィールド名のネーミングルールを周知する、というアプローチにした</li>
<li>例えば、利用する言語を"language"というフィールドの値として設定し、template側でそれに合わせて適切なanalyzerを定義しておくことで、多言語に対してもうまくindexできる.</li>
<li>個人的な感想

<ul>
<li>確かに、どんな型にして、どんなanalyzerにして、とかはノウハウの部分になるので、それをtemplateに集約するのはとても良いアプローチだと思った</li>
</ul>
</li>
</ul>


<h2>elasticsearchソースコードを読みはじめてみた @furandon_pig 氏</h2>

<ul>
<li>Elasticsearchのソースコードを読み始めてみた</li>
<li>開発者の人には、はじめにREST APIを受けて検索する部分の動作をみてみるといいよ、と言われたけど、それがどこか分からなかったので、起動の部分を追いかけてみた話</li>
<li>個人的な感想

<ul>
<li>ちょうど、そろそろソースみないと、と思っていたのでそのとっかかりとして大変参考になった</li>
</ul>
</li>
</ul>


<h2>(LT)Elasticsearch RerouteAPIを使ったシャード配置の制御 @pisatoshi 氏</h2>

<ul>
<li><a href="https://speakerdeck.com/pisatoshi/elasticsearch-rerouteapiwoshi-tutasiyadopei-zhi-falsezhi-yu">資料</a></li>
<li>Reroute APIを使って、具体的にどのシャードをどこに配置するとかの制御ができるよ、という話</li>
<li>リバランスを有効にしていると、APIでシャードを別のノードに配置しても、リバランスされてしまうので注意</li>
<li>個人的な感想

<ul>
<li>オチがとてもおもしろかった.</li>
<li>Reroute APIって、制御できるのは良いけど、逆にいちいち制御するのはやってられないし、どーいう場面で使うのだろう、と思った.</li>
</ul>
</li>
</ul>


<h2>(LT)検索のダウンタイム0でバックアップからIndexをリストアする方法 @k_bigwheel 氏</h2>

<ul>
<li><a href="http://www.slideshare.net/kbigwheel/0index-39143333">資料</a></li>
<li>indexのスナップショットを取れるようになったけど、普通にやるとリストア対象のindexを一旦closeしないといけない. サービスの継続を考えると、ダウンタイム無しでやりたい、という話</li>
<li>予めクライアントからはalias経由でアクセスするようにしておく. aliasの切り替えはatomicにできるので、それを利用して、リストア完了後にスッパリ切り替える、という形にする</li>
<li>個人的な感想

<ul>
<li>リストアだけでなく、mappingを変えるためにindexしなおすとか、aliasを使うと便利な場面はありそう</li>
<li>しかし、自分の環境はfluentdで"name-YYYY.MM.DD"の形でindexを作っているので、この場合aliasはどうしたらいいんだろう</li>
</ul>
</li>
</ul>


<h2>全体所感</h2>

<ul>
<li>最近、Elasticsearchを真面目に使い始めてみたので、どのトークも大変参考になった. 特に、 @satully 氏の話は良かった</li>
<li>結構、みんなAWSなんだな</li>
<li>懇親会で、発表についてのもう少し詳しい話とか、他の人がどんな感じに使ってるとか聞けたので、そっちも良かった. しかも参加費無料. 素晴らしい.</li>
<li>主催の@johtaniさん、会場提供のリクルートテクノロジーズさんに感謝.</li>
</ul>

]]></content>
  </entry>
  
</feed>

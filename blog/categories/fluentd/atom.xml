<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Fluentd | Tech Notes]]></title>
  <link href="http://ogibayashi.github.io/blog/categories/fluentd/atom.xml" rel="self"/>
  <link href="http://ogibayashi.github.io/"/>
  <updated>2016-11-10T11:55:12+09:00</updated>
  <id>http://ogibayashi.github.io/</id>
  <author>
    <name><![CDATA[OGIBAYASHI Hironori]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[多種多様なログをFluentd-Elasticsearch-Kibanaしたメモ]]></title>
    <link href="http://ogibayashi.github.io/blog/2016/11/09/fluentd-elasticsearch-kibana/"/>
    <updated>2016-11-09T19:36:46+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2016/11/09/fluentd-elasticsearch-kibana</id>
    <content type="html"><![CDATA[<p>自分のところでは、社内の様々なログをfluentdで集めているのだけど、それらをElasticsearchに入れて、Kibanaで見えるようした話を書いてみる.</p>

<p>Fluentd, Elasticsearch, Kibanaな組み合わせは既に多くの人が使ってるし、ブログ等の記事も沢山ある. けど、いくつか
引っ掛かった点などもあるので、それらを書き留めて置こうと思う.</p>

<h2>要件</h2>

<ul>
<li>fluentdでストリームで集めてるログを、リアルタイムに近い鮮度でKibanaで見たい.

<ul>
<li>見たい、というのは検索したり、集計・可視化したり、ということ</li>
</ul>
</li>
<li>Kibanaでは短期(2日とか)のログが見えれば良い</li>
<li>規模感的には、ログの種類(=fluentdのtag数)が200くらい、流量はピークで2万メッセージ/秒くらい.

<ul>
<li>が、実際には最も流量の多いログは除いたので、この半分〜3分の1くらいの流量</li>
<li>10shard/index にしてあるので、２日分だと4000 shardくらいになる. これはかなり多いと思う</li>
</ul>
</li>
<li>ログの種類が増えたときも、人手をかけずにKibanaで見えるようになって欲しい</li>
</ul>


<h2>構成</h2>

<p>fluentd→Kafka→<a href="https://github.com/treasure-data/kafka-fluentd-consumer">kafka-fluentd-consumer</a>→fluentd→Elasticsearch</p>

<p>な感じ. Elasticsearchへの投入が詰まる、的な話はよくあるけど、Kafkaを挟んでいるのでfluentdの他の経路に影響が出ることは無いようになっている.</p>

<h2>経験した問題と対応</h2>

<h3>fluentdからの投入タイムアウト</h3>

<p>これに出会ったのは大分前なのだけど、流量が多い場合にバッファのサイズが大きくなると、Elasticsearchへの投入でタイムアウトが発生したりした.</p>

<p><code>
2015-09-30 18:02:48 +0900 [warn]: temporarily failed to flush the buffer. next_retry=2015-09-30 18:01:02 +0900 error_class="Fluent::ElasticsearchOutput::ConnectionFailure" error="Could not push logs to Elasticsearch after 2 retries. read timeout reached" plugin_id="object:3fe40898b7d8"
</code></p>

<p>対応として、fluent-plugin-elasticsearchの設定で<code>request_timeout</code>を長めに設定している.</p>

<h3>Size of the emitted data exceeds buffer_chunk_limit</h3>

<p>kafka-fluentd-consumer からログを受けているfluentdで、以下のようなwarningが多発した.</p>

<p><code>
2016-07-31 21:22:51 +0900 [warn]: Size of the emitted data exceeds buffer_chunk_limit.
2016-07-31 21:22:51 +0900 [warn]: This may occur problems in the output plugins ``at this server.``
2016-07-31 21:22:51 +0900 [warn]: To avoid problems, set a smaller number to the buffer_chunk_limit
2016-07-31 21:22:51 +0900 [warn]: in the forward output ``at the log forwarding server.``
</code></p>

<p>fluentdがin_forwardで受け取ったchunkのサイズが、受け側fluentdでのbuffer_chunk_limit(デフォルト8MB)より大きいよ、という
メッセージ.</p>

<p>kafka-fluentd-consumerが大きいchunkで送信していたと思われる. 当時はこれを制御する術は無かったのだけど、issueをあげたら
対応してもらえた. このためにkafka-fluentd-consumerが内部で使っている<a href="https://github.com/komamitsu/fluency">Fluency</a>にも、改修を入れてくれた様子. 有り難い.</p>

<p><a href="https://github.com/treasure-data/kafka-fluentd-consumer/issues/15">https://github.com/treasure-data/kafka-fluentd-consumer/issues/15</a></p>

<p>こんな感じで、Fluencyのバッファ周りのパラメータを指定できるようになったので、<code>fluentd.client.buffer.chunk.retention.bytes</code>がfluentdのbuffer_chunk_limitより小さくなるようにした.
あとは、Elasticsearchに投入するfluentdプロセスの数を多めにして、一つ一つの負荷が大きくならないようにしている.</p>

<p><code>
fluentd.client.buffer.chunk.initial.bytes = 1000000
fluentd.client.buffer.chunk.retention.bytes = 8000000
fluentd.client.buffer.max.bytes = 512000000
</code></p>

<p>実際には、この設定を入れる前の段階で(なぜか)warningが消えていたので、明確にこれの効果があったのかは不明. だけど、その後ログの流量を大分増やしたりしても
出ていないので、多分効果はあったのだろう.</p>

<h3>日付が変わったタイミングでElasticsearchが固まる問題</h3>

<p>時系列データなので、indexは<code>somelog-YYYY.MM.DD</code>のような形で、日毎に分けるようにしている. 一部のログだけを入れていた時は特に問題は無かったのだけど、
全ての(大体200種類の)ログを入れるようにした所、日付が変わった際にElasticsearchへのindexingが固まる、という事象に出会った.</p>

<p><img src="/images/2016/Elasticsearch_indexing_rate.png" alt="Elasticsearch_indexing_rate" /></p>

<p>Elasticsearchのログを見ると、以下のようなログが大量に発生している.</p>

<p><code>
ProcessClusterEventTimeoutException[failed to process cluster event (put-mapping [fluentd]) within 30s]
at org.elasticsearch.cluster.service.InternalClusterService$2$1.run(InternalClusterService.java:349)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
</code></p>

<p>これについては、Elasticsearchのフォーラムで質問をしてみた.
<a href="https://discuss.elastic.co/t/timeout-exception-with-many-time-based-indices-after-00-00/63340/1">https://discuss.elastic.co/t/timeout-exception-with-many-time-based-indices-after-00-00/63340/1</a></p>

<p>mapping等の情報はcluster stateと呼ばれるメタデータで管理されていて、これの更新はシングルスレッドになっている. dynamic mappingを使っている場合、
新規indexの作成時に新たなmappingの作成も発生し、indexの数が多い場合は、これが大量に発生するために固まったような状態になるのだろう、ということ.</p>

<p>対策として、ここで教えてもらったように、翌日分のindexを事前に作成しておくようにした.</p>

<h3>フィールド名にドットが含まれている場合の問題</h3>

<p>色々なログが入って来た結果、フィールド名にドットが含まれているものがあり、以下のようなエラーが発生</p>

<p>```
[2016-11-10 11:30:06,915][DEBUG][action.admin.indices.mapping.put] [ESHOST1] failed to put mappings on indices [[some.log-2016.11.10]], type [fluentd]
MapperParsingException[Field name [somefield.channel] cannot contain &lsquo;.&rsquo;]</p>

<pre><code>    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:277)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:222)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parse(ObjectMapper.java:197)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseProperties(ObjectMapper.java:309)
    at org.elasticsearch.index.mapper.object.ObjectMapper$TypeParser.parseObjectOrDocumentTypeProperties(ObjectMapper.java:222)
    at org.elasticsearch.index.mapper.object.RootObjectMapper$TypeParser.parse(RootObjectMapper.java:139)
    at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:118)
    at org.elasticsearch.index.mapper.DocumentMapperParser.parse(DocumentMapperParser.java:99)
    at org.elasticsearch.index.mapper.MapperService.parse(MapperService.java:549)
    at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:257)
    at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
    at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
    at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
</code></pre>

<p>```</p>

<p>ドットを含むフィールド名の扱いはバージョンによって違っていて、1.xでは可能だったが、2.xでは不可になった.
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.0/breaking_20_mapping_changes.html#_field_names_may_not_contain_dots">https://www.elastic.co/guide/en/elasticsearch/reference/2.0/breaking_20_mapping_changes.html#_field_names_may_not_contain_dots</a></p>

<p>その後、2.4以降では起動時のオプションに<code>-Dmapper.allow_dots_in_name=true</code>を付けると、ドットを含むフィールド名も入るようになった.
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.4/dots-in-names.html">https://www.elastic.co/guide/en/elasticsearch/reference/2.4/dots-in-names.html</a></p>

<p>そして、5.0以降では再びドットを含むフィールドがOKになった. 今使っているElasticsearchは2.4.0なので、オプションで解決することもできたが、
開発者がドットを含まない形にログの形式を変更してくれることになった.</p>

<h3>Kibanaでのindex pattern作成が面倒</h3>

<p>kafka-fluentd-consumerは、Kafkaから読み込むtopicを正規表現のパターンで指定することができて、fluentd tag=topicが増えた場合は自動的に追随してくれる.
なので、ログの種類が増えてもElasticsearchまでは自動的に格納される.</p>

<p>が、Kibanaで見るためにはindex patternの設定が必要になる. これを毎回やるのは面倒なので、どうにかしたい.</p>

<p>同じような要望はあって、この操作をAPIでできるようにして欲しい、というissueが存在している. <a href="https://github.com/elastic/kibana/issues/5199">https://github.com/elastic/kibana/issues/5199</a></p>

<p>結構長く存在するissueだが、対応されてKibana5ではできるようになるらしい.</p>

<p>が、Kibana5はつい先日GAが出たばかり. 使っているのはまだKibana4だ. Kibana4では、index patternを始めKibana上で作ったオブジェクトの定義は、.kibanaというindexに格納されているので、
これを自分で作る方針にする.</p>

<p>.kibanaに格納されているindex patternの定義は、例えばこんな感じ.</p>

<p>```
  {</p>

<pre><code>  "_index": ".kibana",
  "_type": "index-pattern",
  "_id": "log.hiveserver2-*",
  "_version": 2,
  "_score": 1,
  "_source": {
      "title": "log.hiveserver2-*",
      "timeFieldName": "@timestamp",
      "fields": "[{"name":"_index","type":"string","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"_source","type":"_source","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"tag_key","type":"string","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"message","type":"string","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"hostname","type":"string","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"@timestamp","type":"date","count":0,"scripted":false,"indexed":true,"analyzed":false,"doc_values":true},{"name":"_id","type":"string","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"_type","type":"string","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false},{"name":"_score","type":"number","count":0,"scripted":false,"indexed":false,"analyzed":false,"doc_values":false}]"
  }
</code></pre>

<p>  }
```</p>

<p>fieldsの中身がちょっと面倒. 基本的には、既存のindexのmappingを取得し、Kibanaのソースコードを参考にしながら定義を作る.</p>

<p><a href="https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_map_field.js">https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_map_field.js</a>
<a href="https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_cast_mapping_type.js">https://github.com/elastic/kibana/blob/4.6/src/ui/public/index_patterns/_cast_mapping_type.js</a></p>

<p>例えば、<code>indexed</code>フィールドは、mappingの中の<code>index</code>フィールドが存在しない、または<code>no</code>のときのみ<code>false</code>として、その他の場合は<code>true</code>にする. とか、ElasticsaerchとKibanaでは型が違うので、long→numberみたいに変換する、とか.</p>

<p>これも、日次のバッチで回すようにした</p>

<h2>まとめ</h2>

<ul>
<li>こんな感じで様々なログを、Elasticsearch+Kibanaで見ることができるようになった.</li>
<li>fluentd→Elasticsearchについては、以下の部分がキャパシティ的に問題になりやすい印象

<ul>
<li>fluentd: 流量が多いと普通にCPUが上がって詰まる. 対策として、プロセスを増やして負荷分散する</li>
<li>Elasticsearch: 流量よりは、index数(shard数)が増えることに対して注意がいる. 流量はスケールアウトで対応できるが、cluster state管理の部分はスケールしない. 今回は、日付が切り替わった際の翌日分index作成で問題がおきたので、事前にindexを作成することで対応した. できるだけ、index数は多くなりすぎないように設計した方が良いと思う.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FluentdのFilter&Label周りのコードを読んだメモ]]></title>
    <link href="http://ogibayashi.github.io/blog/2015/03/24/code-reading-of-fluentd-v0-dot-12-filter-and-label-related/"/>
    <updated>2015-03-24T13:45:46+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2015/03/24/code-reading-of-fluentd-v0-dot-12-filter-and-label-related</id>
    <content type="html"><![CDATA[<p>Fluentd v0.12の目玉機能としてFilterとLabelがある. この機能の導入にあたってはメッセージのルーティングを行う部分のコードがガラリと変わっているはずなので、興味本位で読んでみた.</p>

<h2>機能についての参考文書</h2>

<p>そもそもFilterやLabelって何？というあたりは以下が参考になる。</p>

<ul>
<li><a href="http://repeatedly.github.io/ja/2014/08/fluentd-filter-and-label/">Fluentd v0.12でのFilterとLabel</a></li>
<li><a href="http://www.fluentd.org/blog/fluentd-v0.12-is-released">Fluentd v0.12 is Released</a></li>
<li><a href="http://qiita.com/muran001/items/f73d19398b750abb9c2d">Fluentd v0.12の目玉機能らしいFilterを試してみた</a></li>
<li><a href="http://qiita.com/sonots/items/a01d2233210b7b059967">Fluentd v0.12 ラベル機能の使い方とプラグインの改修方法</a></li>
</ul>


<h2>v0.10ではどうだったか</h2>

<p>Matchクラスが<code>match</code>ディレクティブで宣言されたタグのパターンと、行き先のOutputクラスを保持していて、<code>EngineClass#emit</code> (最終的な呼び出し先は<code>emit_stream</code>)で該当するMatchを探し出し、そこに向けて<code>emit</code>する、という形だった.</p>

<p>```ruby
  def emit_stream(tag, es)</p>

<pre><code>  target = @match_cache[tag]
  unless target
    target = match(tag) || NoMatchMatch.new
    # this is not thread-safe but inconsistency doesn't
    # cause serious problems while locking causes.
    if @match_cache_keys.size &gt;= MATCH_CACHE_SIZE
      @match_cache.delete @match_cache_keys.shift
    end
    @match_cache[tag] = target
    @match_cache_keys &lt;&lt; tag
  end
  target.emit(tag, es)
</code></pre>

<p>```</p>

<p>なので、ルーティングを管理するテーブルは<code>EngineClass</code>の<code>@matches</code>一つだったし、tagがルーティングのキーになっていた. 複数のOutputで順番に処理したい場合は都度tagを書き換えていく必要があった.</p>

<h2>v0.12の場合</h2>

<p><code>Agent</code>, <code>RootAgent</code>, <code>Label</code>, <code>EventRouter</code>と言った新しいクラスが導入されている.</p>

<ul>
<li><code>Label</code>

<ul>
<li>各<code>label</code>ディレクティブの中に存在するFilterおよびOutputプラグインを管理するクラス</li>
</ul>
</li>
<li><code>RootAgent</code>

<ul>
<li><code>label</code>ディレクティブに属さない(設定ファイルのルート直下にある)Input, Filter, Outputプラグイン、および各Labelクラスを管理するクラス</li>
</ul>
</li>
<li><code>Agent</code>

<ul>
<li><code>RootAgent</code>および<code>Label</code>の親クラス.</li>
</ul>
</li>
<li><code>EventRouter</code>

<ul>
<li>ルーティングのためのルール(どのタグパターンに対して、どのようなfilterやmatchが存在するか)を管理し、イベントのルーティングを行うクラス</li>
</ul>
</li>
</ul>


<p><code>RootAgent</code>および<code>Label</code>のインスタンスは、それぞれ自分自身が管理する範囲のルーティングを行う<code>EventRouter</code>クラスのインスタンスを保持している.</p>

<p>以下、実際のコードを見てみる.</p>

<h2>起動部分</h2>

<p>まずは、configurationを読み込んでいく段階でどのようなクラスが生成されていくのかを見てみる.</p>

<h3>Supervisor#start (init_engine)</h3>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/supervisor.rb#L124">Supervisor#start</a></p>

<p>Supervisorが起動して、色々と準備していく部分. <code>init_engine</code>内で <a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/engine.rb#L41">Engine#init</a> が呼ばれ、ここで<code>RootAgent</code>が生成される.</p>

<p><code>RootAgent</code>の親クラスである<code>Agent</code>のコンストラクタは以下のようになっている</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/agent.rb#L29">Agent#initialize</a></p>

<p>```ruby</p>

<pre><code>def initialize(opts = {})
  super()

  @context = nil
  @outputs = []
  @filters = []
  @started_outputs = []
  @started_filters = []

  @log = Engine.log
  @event_router = EventRouter.new(NoMatchMatch.new(log), self)
  @error_collector = nil
end
</code></pre>

<p>```</p>

<p>自身が管理するOutputクラス、Filterクラス達を保持するための変数が存在している. また、そのスコープでのルーティングを行う<code>EventRouter</code>クラスをここで生成している.</p>

<p><code>RootAgent</code>については、これに加えて更にInputやLabelクラスも管理するような構造になっている. (<a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/root_agent.rb#L46">root_agent.rb</a>)</p>

<h3>Supervisor#start (run_configure)</h3>

<p><code>Supervisor#run_conigure</code>が呼ばれると、<code>Engine#configure</code>を経由して<code>RootAgent#configure</code>が呼ばれる.</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/root_agent.rb#L62">RootAgent#configure</a></p>

<p>ちょっと長いが引用.これにより以下が行われる</p>

<ul>
<li>labelディレクティブがあった場合

<ul>
<li> <a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/root_agent.rb#L155">add_label</a>により新規<code>Label</code>オブジェクトを生成</li>
<li> さらに、その<code>Label</code>オブジェクトの<code>configure</code>を呼び出す. <code>configure</code>の内容については、以下の<code>Agent#configure</code>を参照.</li>
</ul>
</li>
<li>sourceディレクティブがあった場合

<ul>
<li><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/root_agent.rb#L141">add_source</a>によりInputプラグインのインスタンスを生成</li>
<li>Inputプラグインがemitする際の投げ先として、以下を登録.

<ul>
<li>そのInputプラグインで<code>@label</code>が設定されている場合→設定された<code>Label</code>オブジェクトの<code>EventRouter</code>を登録</li>
<li>それ以外の場合→<code>RootAgent</code>の<code>EventRouter</code>を登録</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Inputプラグインについては<code>@label</code>が設定されている場合とそうでない場合で、emit先の<code>EventRouter</code>を切り替えることができるようになっている.</p>

<p>```ruby</p>

<pre><code>def configure(conf)
  error_label_config = nil

  # initialize &lt;label&gt; elements before configuring all plugins to avoid 'label not found' in input, filter and output.
  label_configs = {}
  conf.elements.select { |e| e.name == 'label' }.each { |e|
    name = e.arg
    raise ConfigError, "Missing symbol argument on &lt;label&gt; directive" if name.empty?

    if name == ERROR_LABEL
      error_label_config = e
    else
      add_label(name)
      label_configs[name] = e
    end
  }
  # Call 'configure' here to avoid 'label not found'
  label_configs.each { |name, e| @labels[name].configure(e) }
  setup_error_label(error_label_config) if error_label_config

  super

  # initialize &lt;source&gt; elements
  if @without_source
    log.info "'--without-source' is applied. Ignore &lt;source&gt; sections"
  else
    conf.elements.select { |e| e.name == 'source' }.each { |e|
      type = e['@type'] || e['type']
      raise ConfigError, "Missing 'type' parameter on &lt;source&gt; directive" unless type
      add_source(type, e)
    }
  end
end
</code></pre>

<p>```</p>

<p>さらに、<code>RootAgent</code>の親クラスである<code>Agent#configure</code>では同様にmatchに対して<code>add_match</code>、filterについて<code>add_filter</code>が呼ばれる.</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/agent.rb#L50">Anget#configure</a></p>

<p>```ruby</p>

<pre><code>def configure(conf)
  super

  # initialize &lt;match&gt; and &lt;filter&gt; elements
  conf.elements.select { |e| e.name == 'filter' || e.name == 'match' }.each { |e|
    pattern = e.arg.empty? ? '**' : e.arg
    type = e['@type'] || e['type']
    if e.name == 'filter'
      add_filter(type, pattern, e)
    else
      add_match(type, pattern, e)
    end
  }
end
</code></pre>

<p>```</p>

<p><code>Agent</code>は<code>Label</code>の親クラスでもあるので、新しい<code>Label</code>オブジェクトの<code>configure</code>が呼び出された際もこのコードが実行されることになる.</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/agent.rb#L134">add_filter</a>や<a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/agent.rb#L122">add_match</a>が何をしているかというと、その<code>Agent</code>が持っている<code>EventRouter</code>に対してルーティングのルール(<code>Rule</code>オブジェクト)を登録している.</p>

<h3>絵にすると、、、</h3>

<p><a href="http://www.fluentd.org/blog/fluentd-v0.12-is-released">FluentdのBlog</a>に書かれているサンプルを元に、どんな感じのオブジェクトたちが出来上がるかを絵にするとこんな感じ.</p>

<p><img src="/images/2015/201503_Fluentd_Routing.png" alt="RootAgent" /></p>

<p>labelごとにルーティングテーブルを持つので、labelが違えば異なるルールでルーティングする、ということができるようになる.</p>

<h2>emitの動き</h2>

<p>ここまでで、各Input, Filter, Outputプラグインインスタンスは、自分がemitする先の<code>EventRouter</code>オブジェクトを知っていることになる.</p>

<p>まず、Inputプラグイン内では自分が知っている<code>EventRouter</code>に<code>emit</code>する.</p>

<p><code>ruby
router.emit(tag, time, record)
</code></p>

<p><code>emit</code>は<code>emit_stream</code>に飛ぶので、以下のコードが呼び出される. <code>match</code>メソッドが返してきたオブジェクトに対して<code>emit</code>する.</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/event_router.rb#L87">EventRouter#emit_stream</a></p>

<p>```ruby</p>

<pre><code>def emit_stream(tag, es)
  match(tag).emit(tag, es, @chain)
rescue =&gt; e
  @emit_error_handler.handle_emits_error(tag, es, e)
end
</code></pre>

<p>```</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/event_router.rb#L101">EventRouter#match</a> に飛ぶ. <code>match</code>はemitされたtagを受け取るべきCollectorを返す.</p>

<p>```ruby</p>

<pre><code>def match(tag)
  collector = @match_cache.get(tag) {
    c = find(tag) || @default_collector
  }
  collector
end
</code></pre>

<p>```</p>

<p>このCollectorを探す部分がどうなっているかと言うと、</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/event_router.rb#L156">event_router#find</a></p>

<p>こんな感じになっている. つまり、Filterが使われていれば<code>Pipeline</code>オブジェクトを生成してそこにFilterやOutputを順次追加していく. Filterがなければ<code>Pipeline</code>の代わりにOutputを直接返す.</p>

<p>```ruby</p>

<pre><code>def find(tag)
  pipeline = nil
  @match_rules.each_with_index { |rule, i|
    if rule.match?(tag)
      if rule.collector.is_a?(Filter)
        pipeline ||= Pipeline.new
        pipeline.add_filter(rule.collector)
      else
        if pipeline
          pipeline.set_output(rule.collector)
        else
          # Use Output directly when filter is not matched
          pipeline = rule.collector
        end
        return pipeline
      end
    end
  }

  if pipeline
    # filter is matched but no match
    pipeline.set_output(@default_collector)
    pipeline
  else
    nil
  end
end
</code></pre>

<p>```</p>

<p>よって、<code>emit</code>されたレコードは<code>Pipeline</code>または<code>Output</code>に<code>emit</code>されることになる. そして、<code>Pipeline</code>に<code>emit</code>された場合は以下のコードに辿り着き、順番にFilterを通った後に最終的にOutputに<code>emit</code>されることになる.</p>

<p><a href="https://github.com/fluent/fluentd/blob/f6aa9a4b275e4e9885bb912bcf0e930966d8e246/lib/fluent/event_router.rb#L147">Pipeline#emit</a></p>

<p>```ruby</p>

<pre><code>  def emit(tag, es, chain)
    processed = es
    @filters.each { |filter|
      processed = filter.filter_stream(tag, processed)
    }
    @output.emit(tag, processed, chain)
  end
</code></pre>

<p>```</p>

<p>このようにFilterを実現するためにPipelineという新しい仕組みを導入しているため、tagの書き換えによる多段フィルタをしなくて済むようになっている.</p>

<h2>まとめ</h2>

<ul>
<li>v0.12のLabel, Filterを実現している部分のコードを読んでみた</li>
<li>Labelの部分は、RootAgent(設定ファイルのROOT部分)および各labelディレクティブごとにルーティングテーブル(<code>EventRouter</code>)を分けることにより実現されている</li>
<li>Filterは、レコードに対する連続した処理を表現する、Pipelineという新たな仕組みを導入することで実現されている</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentdで Incompatible Character Encodingのエラーが出た話]]></title>
    <link href="http://ogibayashi.github.io/blog/2015/02/28/incompatible-character-encodings-in-fluentd/"/>
    <updated>2015-02-28T22:24:31+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2015/02/28/incompatible-character-encodings-in-fluentd</id>
    <content type="html"><![CDATA[<p>Fluentdに対して、in_httpのインタフェースで送信してくるアプリケーションがあるのだけど、そのアプリケーションに対してリリースがあった後、一部のメッセージがうまく送れないという話があった. 見てみたら、受信側Fluentdに以下のようなメッセージが多発していた. fluentdのバージョンは0.10.48.</p>

<p><code>``
2015-02-06 14:14:52 +0900 [warn]: fluent/engine.rb:156:rescue in emit_stream: em
it transaction failed  error_class=Encoding::CompatibilityError error=#&lt;Encoding
::CompatibilityError: incompatible character encodings: ASCII-8BIT and UTF-8&gt;
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/event.rb:32:in
</code>&lt;&lt;&lsquo;
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/event.rb:32:in
<code>to_msgpack'
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/event.rb:32:in
</code>block in to_msgpack_stream&rsquo;
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/event.rb:54:in
<code>call'
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/event.rb:54:in
</code>each'
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/event.rb:31:in
<code>to_msgpack_stream'
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/output.rb:424:i
n</code>emit'
  2015-02-06 14:14:52 +0900 [warn]: plugin/in_http.rb:147:on_request: /opt/td-ag
ent/embedded/lib/ruby/gems/2.1.0/gems/fluentd-0.10.48/lib/fluent/output.rb:33:in
 `next'</p>

<p>```</p>

<p>全てのメッセージが送れてないわけではない模様. 適当なメッセージをcurlで送ってみても問題ないので
なんだろう、、、と思っていたら、以下のpull requestを見つけた. 偶然、事象が発生したのと同日.</p>

<p><a href="https://github.com/fluent/fluentd/pull/550">https://github.com/fluent/fluentd/pull/550</a></p>

<p>Messagepackの不具合?で、5KBを超える、且つエンコードがASCII-8BIT以外の文字列をシリアライズしようとした時に、このエラーが出ることがあるそうな. msgpack 0.5.11で修正.</p>

<p>アプリケーションの人に聞いてみると、確かにメッセージサイズは大幅に増えているようだし、エラー発生時のパケットを見ても、メッセージサイズが数百KBととても大きい. このpull requestは v0.10.60で取り込まれているようなので、td-agentを2.1.4に上げてテストをしてみたら発生しなくなった.</p>

<p>もっと前にこれが発生してたら困ってただろうな. ちょうど修正されてて助かりました.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentd v0.12のAt-least-once Semanticsを試す]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/12/16/try-fluentd-v0-dot-12-at-least-once/"/>
    <updated>2014-12-16T00:34:17+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/12/16/try-fluentd-v0-dot-12-at-least-once</id>
    <content type="html"><![CDATA[<p>Fluentd v0.12のin/out_forwardでAt-least-once semanticsがサポートされるようになった. 今まではアプリケーションレイヤでの到達確認がなかったので、一部のネットワーク障害などのケースでは、送信されたように見えて実は送信されていない、という事象が発生し得た. v0.12から導入された<code>require_ack_response</code>オプションを使うと、このような事象を避けることができる.</p>

<p>この機能が導入されたpull requestはこちら.
<a href="https://github.com/fluent/fluentd/pull/428">https://github.com/fluent/fluentd/pull/428</a></p>

<p>ということで試してみた.</p>

<h2>require_ack_responseがない場合</h2>

<p>fluentd 0.10.56で試す. (0.12で試しても良かったのだけど..)</p>

<p>送信側は以下の設定. 相手先fluentdが早々にdetachされてしまうのを避けるため、<code>hard_timeout</code>と<code>phi_threshold</code>を入れた</p>

<p>```
<source>
   type forward
</source>
<match test.**>
   type forward
   flush_interval 1s
   heartbeat_type tcp
   hard_timeout 600
   phi_threshold 300
   buffer_type file
   buffer_path /var/log/fluentd.*.buffer
   <server></p>

<pre><code> host  192.168.1.2
 port 24224
</code></pre>

<p>   </server>
</match></p>

<p>```</p>

<p>受信側はこんな感じ</p>

<p>```
<source>
  type forward
</source></p>

<p><match test.**>
  type file
  path /tmp/fluentd_forward.log
</match></p>

<p>```</p>

<p>で、パケットが届かないが、アプリケーションにエラーが返らない状況を作るため、受信側のiptablesでSYNが立っていないパケットをドロップするようにする. SYNは相手に到達し、SYN-ACKも返るため、アプリケーションからは正常に接続されている様に見えることになる.</p>

<p>```</p>

<h1>iptables -A INPUT -p tcp &mdash;syn &mdash;dport 24224 -j ACCEPT</h1>

<h1>iptables -A INPUT -p tcp &mdash;dport 24224 -j DROP</h1>

<p>```</p>

<p>これでログを送ってみる</p>

<p>```</p>

<h1>echo &lsquo;{&ldquo;aaa&rdquo;: 1}&rsquo; | fluent-cat  test.data</h1>

<h1>echo &lsquo;{&ldquo;bbb&rdquo;: 2}&rsquo; | fluent-cat test.data</h1>

<p>```</p>

<p>netstatで送信側のソケットを見る. Send-Qにデータが溜まっている.</p>

<p>```</p>

<h1>netstat -na | grep 24224</h1>

<p>tcp        0      0 0.0.0.0:24224               0.0.0.0:<em>                   LISTEN
tcp        0      1 192.168.1.1:10652          192.168.1.2:24224          FIN_WAIT1
tcp        0     41 192.168.1.1:10655          192.168.1.2:24224          FIN_WAIT1
udp        0      0 0.0.0.0:24224               0.0.0.0:</em></p>

<p>```</p>

<p>しばらくすると、ソケットが破棄される.</p>

<p>```</p>

<h1>netstat -na | grep 24224</h1>

<p>tcp        0      0 0.0.0.0:24224               0.0.0.0:<em>                   LISTEN    <br/>
tcp        0      1 192.168.1.1:10664           192.168.1.2:24224          FIN_WAIT1 <br/>
udp        0      0 0.0.0.0:24224               0.0.0.0:</em></p>

<p>```</p>

<p>この状況だと、アプリケーション的には正常に送れているように見えてしまうので、バッファは削除される. つまりログがロストした状況.</p>

<p>```</p>

<h1>ls /var/log/fluentd.*.buffer</h1>

<p>ls: cannot access /var/log/fluentd.*.buffer: そのようなファイルやディレクトリはありません</p>

<p>```</p>

<h2>require_ack_responseを使う</h2>

<p>次に、送受信共に<code>v0.12.1</code>にして、送信側に<code>require_ack_response</code>の設定を入れてみる.</p>

<p>```
  <source></p>

<pre><code>type forward
</code></pre>

<p>  </source>
  <match test.**></p>

<pre><code>type forward
flush_interval 1s
heartbeat_type tcp
hard_timeout 600
phi_threshold 300
buffer_type file
buffer_path /var/log/fluentd.*.buffer
require_ack_response 
&lt;server&gt;
  host 192.168.1.2
  port 24224
&lt;/server&gt;
</code></pre>

<p>  </match></p>

<p>```</p>

<p>同様にfluent-catで送る. 今度は、一定時間後に以下のようにエラーになった.</p>

<p><code>``
2014-12-15 15:25:56 +0900 [warn]: no response from 192.168.1.2:24224. regard it as unavailable.
2014-12-15 15:26:56 +0900 [warn]: temporarily failed to flush the buffer. next_retry=2014-12-15 15:22:46 +0900 error_class="Fluent::ForwardOutputACKTimeoutError" error="node 10.29.254.66:24224 does not return ACK" plugin_id="object:16c7e3c"
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/plugin/out_forward.rb:321:in</code>send_data'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/plugin/out_forward.rb:169:in <code>block in write_objects'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/plugin/out_forward.rb:163:in</code>times'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/plugin/out_forward.rb:163:in <code>write_objects'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/output.rb:459:in</code>write'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/buffer.rb:325:in <code>write_chunk'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/buffer.rb:304:in</code>pop'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/output.rb:320:in <code>try_flush'
  2014-12-15 15:26:56 +0900 [warn]: /usr/local/rvm/gems/ruby-2.1.5/gems/fluentd-0.12.1/lib/fluent/output.rb:140:in</code>run'</p>

<p>```</p>

<p>バッファも残っている</p>

<p>```</p>

<h1>ls /var/log/fluentd.test.data.*.buffer</h1>

<p>/var/log/fluentd.test.data.b50a3b457dcfed028.buffer  /var/log/fluentd.test.data.q50a3b455b1eac4ca.buffer
```</p>

<p>しばらく放置した後、iptablesを解除したら無事に送信された.</p>

<h2>まとめ</h2>

<p>Fluentd v0.12で導入されたAt-least-once semanticsを試してみた. アプリケーションレイヤでの到達確認が実装されることで、TCPレイヤでパケットがうまく届いていないケースについても、fluentdがそれを検知して再送してくれることが確認できた.</p>

<p>ちなみに自分のところでは、ruby1.9上でfluentdを動かしていた時にプロセスが短時間ブロックするような事象が多発していて、それに起因してログのロストが発生したことがある. 恐らく、上記のようにTCPのコネクションは確立したように見えて、実は相手側がハング状態だったためにソケットバッファに滞留、最終的にソケットクローズ時にパケットが破棄されたのだと考えている.
(この時は、td-agent2にしたら解消した)</p>

<p><code>require_ack_response</code>により、そのようなケースでもfluentdがちゃんと検知して再送してくれるので、このオプションは是非入れておきたい.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentdの障害時動作]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/06/04/how-fluentd-works-in-case-of-failures/"/>
    <updated>2014-06-04T23:12:23+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/06/04/how-fluentd-works-in-case-of-failures</id>
    <content type="html"><![CDATA[<p>Fluentdが障害の時にどのような動作をするのか調べてみたので、そのメモ. td-agent 1.1.17(fluentd v0.10.39)で確認したつもりだが、もしかしたらもう少し新しいので確認したケースもあるかも. BufferedOutputを中心に記載している.</p>

<h2>BufferdOutputの基本</h2>

<p>fluentdの特徴の一つとして、fluentd送信先で障害があり、メッセージが送れなかった場合は大抵(BufferedOutputを使っているプラグインであれば)fluentdでバッファリングし、一定時間後に再送してくれる.</p>

<p>このバッファリングのサイズは、BufferedOutputプラグインのbuffer_chunk_limit*buffer_queue_limitで決まる.</p>

<p>これらのデフォルト値は以下に解説付きでまとまっている. (良く参照させて頂いています)
<a href="http://d.hatena.ne.jp/tagomoris/20130123/1358929254">FluentdでバッファつきOutputPluginを使うときのデフォルト値</a></p>

<h2>何回くらいリトライするの？ リトライの間隔は？</h2>

<p>リトライの回数は、retry_limit(デフォルト 17)で指定された回数まで. 間隔は一定ではなく、段々延びていく. 具体的に間隔を計算してるのは、BufferedOutput#calc_retry_wait.</p>

<p>リトライ間隔は、以下のパラメータでコントロールすることができる</p>

<ul>
<li>max_retry_wait(デフォルト: nil = 上限なし)</li>
<li>retry_wait (デフォルト: 1.0)</li>
</ul>


<p>同じメソッドを使って、実際にどれくらいになるのかを計算させてみた. 以下で例えば、1=>2は、一度送信に失敗してから、2回目の送信を試みるまでという意味. 単位は秒. 全てデフォルト値だと、以下の様な感じ. 最大だと、33765秒=9時間22分になる.</p>

<p>```
1=>2 : 1.0799124443510373
2=>3 : 1.8141315928054327
3=>4 : 3.5115188260172046
4=>5 : 7.106397160810471
5=>6 : 14.175590112052593
6=>7 : 31.434005639868758
7=>8 : 68.4743252224448
8=>9 : 116.47949944913451
9=>10 : 279.97276701667636
10=>11 : 487.69976826480445
11=>12 : 909.7729519328531
12=>13 : 2125.0559803853725
13=>14 : 3717.0255349933364
14=>15 : 8658.913465429461
15=>16 : 18189.354025481873
16=>17 : 33765.98470398931</p>

<p>```</p>

<p>例えば、max_retry_wait=120とすると、以下のようになる. 何回リトライしても、リトライ間隔の上限はmax_retry_waitまでになる.</p>

<p>```
1=>2 : 1.0717022666140232
2=>3 : 1.9866738239982864
3=>4 : 3.9258714996769903
4=>5 : 7.002702902759963
5=>6 : 15.817343449261045
6=>7 : 34.49173945537066
7=>8 : 65.98469012616731
8=>9 : 120
9=>10 : 120
10=>11 : 120
11=>12 : 120
12=>13 : 120
13=>14 : 120
14=>15 : 120
15=>16 : 120
16=>17 : 120</p>

<p>```</p>

<p>retry_waitを半分の0.5にすると、全てのリトライ間隔が半分になる.</p>

<p>```
1=>2 : 0.46442639898905974
2=>3 : 0.9688421553729557
3=>4 : 2.2291735347851613
4=>5 : 3.545406346443683
5=>6 : 7.824124603156501
6=>7 : 17.564462446502926
7=>8 : 30.97024814321994
8=>9 : 71.84343582620227
9=>10 : 127.87010583643446
10=>11 : 286.751861977861
11=>12 : 551.32668884554
12=>13 : 1077.2785515357239
13=>14 : 2095.196745718026
14=>15 : 3995.080966184667
15=>16 : 9131.408473518048
16=>17 : 16810.484835714517</p>

<p>```</p>

<p>リトライの頻度を増やす(リトライ間隔を減らす)場合は、併せてretry_limitも変更しないと、早々にリトライアウトしてしまう、ということになるので注意.</p>

<h2>リトライ回数が超過したら？</h2>

<p>リトライ回数を超過した場合、secodaryディレクティブを指定しておけば、そちらに出力される. 通常は、ファイルに出力しておいて、後からリカバリに使う、というケースが多いと思う.</p>

<p>```
  <secondary></p>

<pre><code>type file
path /path/to/forward-failed
</code></pre>

<p>  </secondary>
```</p>

<p>このようなケースでは、ログに以下のように出力される</p>

<p>```
2014-06-22 07:06:40 +0900 [warn]: fluent/output.rb:352:rescue in try_flush: retry count exceededs limit. falling back to secondary output.</p>

<p>```</p>

<h2>キューが溢れたら？</h2>

<p>キュー(バッファ)が溢れると、fluentdのログに以下のようなメッセージが出る.</p>

<p>```
2014-05-25 11:30:23 +0900 [warn]: fluent/engine.rb:149:rescue in emit_stream: emit transaction failed  error_class=Fluent::BufferQueueLimitError error=#&lt;Fluent::BufferQueueLimitError: queue size exceeds limit></p>

<p>```</p>

<p>この場合、inputプラグインがEngine.emitを実行する際にExceptionが発生する. プラグインが、これをrescueしていない場合、inputプラグインは停止する. rescueしている場合はinputプラグインの実装次第だが、大抵Exceptionは無視されてemitしたデータは破棄される.
(既に溜めるためのキューがあふれているので、それしか無い)</p>

<h2>送信先が復活したら?</h2>

<p>再送中に送信先が復活し、再送に成功した場合は以下の様なメッセージが出力される.</p>

<p><code>
2014-05-25 11:33:01 +0900 [warn]: fluent/output.rb:312:try_flush: retry succeeded. instance=70365422937420
</code></p>

<p>ここで、注意点として送信先が復活してもすぐに再送してくれるわけではない. これは、送信先とのハートビートを行っているout_forwardでも一緒. BufferedOutput#try_flushのコードを見ると分かるが、リトライ中で、まだ次のリトライ時刻に達していない場合は、送信は行わない.</p>

<p>なので、retryを繰り返して再送間隔が延びている場合は、次の再送タイミングになるまでキューが溜まり続ける(もしくは、既に溢れている場合は溢れ続ける)</p>

<h2>キューを強制的に送信することはできないの？</h2>

<p>v0.10.59以前の場合 → リトライ中の場合以外であれば、fluentdのプロセスにSIGUSR1を送ることでキューが吐き出される. リトライ中の場合は、次のリトライタイミングまでは送信されない.全てのキューを吐き出すには、プロセスを停止するしかない.</p>

<p>v0.10.59以降の場合 → リトライ中の場合含め、fluentdのプロセスにSIGUSR1を送ることでキューが吐き出される. (2014/4/4追記: @sonotsさんに頂いたコメントを反映しました)</p>

<p>プロセス停止時の挙動は使用しているバッファプラグインによって異なるが</p>

<ul>
<li>buf_memoryの場合

<ul>
<li>プロセス停止時に全てのキューが吐き出される.</li>
</ul>
</li>
<li>buf_fileの場合

<ul>
<li>flush_at_shutdownがtrue(デフォルト false)の場合のみ、プロセス停止時に全てのキューが吐き出される.</li>
</ul>
</li>
</ul>


<p>長くなったのでここまで.</p>
]]></content>
  </entry>
  
</feed>

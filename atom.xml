<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tech Notes]]></title>
  <link href="http://ogibayashi.github.io/atom.xml" rel="self"/>
  <link href="http://ogibayashi.github.io/"/>
  <updated>2014-09-27T09:52:46+09:00</updated>
  <id>http://ogibayashi.github.io/</id>
  <author>
    <name><![CDATA[OGIBAYASHI Hironori]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Getting Stated With OpenShiftを読んだ]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/09/27/getting-started-with-openshift/"/>
    <updated>2014-09-27T08:16:08+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/09/27/getting-started-with-openshift</id>
    <content type="html"><![CDATA[<p><a href="http://shop.oreilly.com/product/0636920033226.do">Getting Stated with OpenShift</a>を読んだので、簡単にまとめ. とりあえず4章まで.</p>

<h2>この本について</h2>

<p>OpenShiftの管理者ではなく、Webアプリケーション開発者向けの本. OpenShift Onlineを使って、どのようにWebアプリケーションを動かすことができるか、ということが書いてある</p>

<h2>1. Introduction</h2>

<ul>
<li>OpenShiftとは？

<ul>
<li>RedHatが提供するPaaS</li>
</ul>
</li>
<li>3つのバージョンがある

<ul>
<li>OpenShift Origin : オープンソースであり、最新版. 自分の環境に入れて使うことができる. OnlineやEnterpriseのUpstreamとなる.</li>
<li>OpenShift Online : RedHatが提供するクラウドサービス版. AWS上で動いており、アカウントを作ればOpenShiftの環境を使うことができる.  本書はこれを対象に書かれている.</li>
<li>OpenShift Enterprise : Productionでの利用を想定し、RedHatによりサポートされる安定版. 自分でインストールして使う.</li>
</ul>
</li>
<li>基本的な用語

<ul>
<li>Application : OpenShift上で動かすWebアプリケーション</li>
<li>Gear : サーバコンテナ. 使えるリソースに応じて、small, medium, largeの3タイプがある</li>
<li>Cartridge: Gearに追加する機能の固まり. JBossとか、Pythonとか、DatabaseとかCronとか.</li>
</ul>
</li>
</ul>


<h2>2. Creating Application</h2>

<ul>
<li>OpenShift Onlineを使うための流れは以下の通り

<ul>
<li>アカウントを作る</li>
<li>コマンドラインツール(rhc)を入れる. rhcはrubygemなので、<code>gem install rhc</code>で入れることができる</li>
<li>コマンドラインツールをセットアップする. <code>rhc setup</code>で行う. OpenShiftのAPIをコマンドラインから使うための認証情報などを登録する.</li>
</ul>
</li>
<li>以後、OpenShift上のアプリケーション管理は<code>rhc</code>コマンドで行う</li>
<li>OpenShiftのアプリケーションを作るには<code>rhc app create insultapp python-2.7</code>のようにする. 引数は、アプリケーション名と言語.

<ul>
<li>実行すると、アプリケーションにアクセスするためのURLや、GearにSSHログインするためのユーザ名@ホスト名が表示される</li>
<li>また、カレントディレクトリにGitリポジトリが作成される. このリポジトリ内にアプリケーションのコードや色々な設定が格納される.</li>
</ul>
</li>
<li>アプリケーションを作成する際に、 <code>-g</code>オプションを付けるとautoscaling機能が有効になる. 有効にすると、HAProxyがセットアップされ、アプリケーションがスケールアウトできるようになる

<ul>
<li>本書では簡略化のためautoscalingは使っていないが、有効にしておいた方が良い</li>
</ul>
</li>
<li>smallのgearであれば無償で使える. 無償版の場合、48時間リクエストが無いとアプリケーションは一旦ディスクに書かれ、次回リクエスト時に再ロードされる (応答に時間がかかる)

<ul>
<li>お金を払えば、gearを増やしたり、より大きなgearを使ったり、ディスク容量を拡張したり、JBoss EAP等の有償Cartridgeを使ったり、サポートチケットを発行したり、などなどができる.</li>
</ul>
</li>
</ul>


<h2>3. Making Code Modifications</h2>

<ul>
<li>アプリケーション作成時に作成されたGitリポジトリ内にコードを書いて、<code>git push</code>するとデプロイされる</li>
<li><code>.openshift/action_hooks</code>ディレクトリ内にファイルを作成しておくことで、デプロイの特定のタイミングで任意の処理を実行することができる. (action hook script)</li>
<li>通常、アプリケーションのデプロイ時にアプリケーションは一旦停止する. <code>.openshift/markers/hot_deploy</code> ファイルを作成しておくと、ホットデプロイが有効になる.</li>
</ul>


<h2>4. Adding Application Components</h2>

<ul>
<li>Cartridgeを追加することで、アプリケーションに様々な機能を追加することができる(<code>rhc cartridge add &lt;cartridge名&gt;</code>). この章では以下のCartridgeが紹介されている.</li>
<li>Database

<ul>
<li>PostgreSQL, MySQL, MongoDB等のデータベースを使うことができる</li>
<li>アプリケーションがscalableでなければ同じgearに、そうでなければDatabase専用gearが作成され、その中にインストールされる</li>
<li>追加時に、DBへアクセスするためのアカウントやURL等が表示される</li>
</ul>
</li>
<li>Cron

<ul>
<li>cronを使うことができる</li>
<li>git repositoryの<code>openshift/cron/{minutely,hourly,daily,weekly,monthly}/</code>以下にファイルを作成し、<code>git push</code>すると有効になる</li>
</ul>
</li>
<li>Continuous Integration (jenkins)

<ul>
<li>まず、<code>rhc app create</code>でJenkins用のアプリケーションを作成する</li>
<li>その上で、元のアプリケーションに<code>rhc cartridge add</code>でJenkinsのクライアントをCartridgeとして追加.</li>
<li>これにより、アプリケーションをpushした際にJenkins上でビルドやテストが走るようになる. ビルドが失敗した場合、アプリケーションはデプロイされない</li>
</ul>
</li>
<li>Metrics and Monitoring

<ul>
<li><code>rhc cartridge add metrics-0.1 -a appname</code>のようにすることで、アプリケーションのモニタリング画面が追加される. CPUやメモリの状況等を確認可能</li>
</ul>
</li>
<li>その他にも、コミュニティで開発された多数のCartridgeが存在し、利用することができる.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第6回Elasticsearch勉強会]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/09/17/elasticsearch-study-6th/"/>
    <updated>2014-09-17T00:19:06+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/09/17/elasticsearch-study-6th</id>
    <content type="html"><![CDATA[<p>第6回Elasticsearch勉強会に参加したので、記憶が新しいうちにメモ. 内容は資料を見れば分かると思うので、個人的に特に記憶に残ったポイントと、感想のみ.</p>

<h2>Aggregationあれこれ @johtani 氏</h2>

<ul>
<li>ElasticsearchのAggregation機能を使うと、SQLで言う集計 group by 的なものができると、という話</li>
<li>動きとしては、各shard内でaggregateし、最後にその結果を集約する、という形. 普通のqueryと変わらない</li>
<li>クエリの種類によっては、正確な値ではなく近似値だったりする</li>
<li>Field Collapsingという、URLごとにtop Nを検索するようなこともできる</li>
<li>個人的な感想

<ul>
<li>便利な機能なので、是非使いたい. 現状だとKibana3で使えないのがネックだけど、Kibana4だと使えるようになるらしいので期待</li>
</ul>
</li>
</ul>


<h2>秒間3万の広告配信ログをElasticSearchで リアルタイム集計してきた戦いの記録 @satully 氏</h2>

<ul>
<li><a href="http://www.slideshare.net/Satully/elasticsearch-study6threaltime20140916">資料</a></li>
<li>商用での利用事例、という意味ですごく興味深かった</li>
<li>DSPの配信システムで利用. 最大秒間30000ログ. 1.5TB/日くらい</li>
<li>各サーバのログ &ndash;> fluentd &ndash;> Elasticsearch &ndash;> MySQL/Redis という構成</li>
<li>fluentdは10インスタンス</li>
<li>ElasticsearchはCoordinate:2ノード, Search:2ノード, Data:28ノード.全てAWSのr3.largeインスタンス. メモリは30GBくらい？

<ul>
<li>diskは途中でSSDに変えた</li>
<li>CoordinateとSearchを分離する、というのは世間で見かけるけど、実際に負荷をみると必要性が疑問</li>
<li>1日1index, 1index12shard, 1レプリ.</li>
</ul>
</li>
<li>単純なログのinsertのみではなく、Bidと紐付けるべきログが来ると、元のBidのログに項目を追加する. fluentd pluginとして実装</li>
<li>運用ツールとしては、Elasticsearchのpluginとしてhead, bigdesk, ElasticHQ. 死活監視やfluentdのメトリックにはZABBIX</li>
<li>個人的な感想

<ul>
<li>サーバスペック、台数、流量の具体的な事例としてとても参考になった</li>
<li>indexサイズはかなり大きくなるけど、いけるものなんだ.</li>
<li>お金の計算に関わる部分に、fluentdとかElasticsearchとか使っている、というのに驚いた</li>
</ul>
</li>
</ul>


<h2>Elasticsearch 日本語スキーマレス環境構築と、ついでに多言語対応 @9215 氏</h2>

<ul>
<li><a href="https://speakerdeck.com/kunihikokido/elasticsearch-ri-ben-yu-sukimaresuhuan-jing-gou-zhu-to-tuideniduo-yan-yu-dui-ying">資料</a></li>
<li>スキーマをちゃんと設計して、それに合わせてマッピング定義するのは面倒. どんなフィールドでどんなマッピングが最適、とか個別に設計すると人材がスケールしない.</li>
<li>そこで、dynamic templateとindex templateを使い、ノウハウが必要な部分はtemplateに集約、各利用者(データを投入する人)にはフィールド名のネーミングルールを周知する、というアプローチにした</li>
<li>例えば、利用する言語を&#8221;language&#8221;というフィールドの値として設定し、template側でそれに合わせて適切なanalyzerを定義しておくことで、多言語に対してもうまくindexできる.</li>
<li>個人的な感想

<ul>
<li>確かに、どんな型にして、どんなanalyzerにして、とかはノウハウの部分になるので、それをtemplateに集約するのはとても良いアプローチだと思った</li>
</ul>
</li>
</ul>


<h2>elasticsearchソースコードを読みはじめてみた @furandon_pig 氏</h2>

<ul>
<li>Elasticsearchのソースコードを読み始めてみた</li>
<li>開発者の人には、はじめにREST APIを受けて検索する部分の動作をみてみるといいよ、と言われたけど、それがどこか分からなかったので、起動の部分を追いかけてみた話</li>
<li>個人的な感想

<ul>
<li>ちょうど、そろそろソースみないと、と思っていたのでそのとっかかりとして大変参考になった</li>
</ul>
</li>
</ul>


<h2>(LT)Elasticsearch RerouteAPIを使ったシャード配置の制御 @pisatoshi 氏</h2>

<ul>
<li><a href="https://speakerdeck.com/pisatoshi/elasticsearch-rerouteapiwoshi-tutasiyadopei-zhi-falsezhi-yu">資料</a></li>
<li>Reroute APIを使って、具体的にどのシャードをどこに配置するとかの制御ができるよ、という話</li>
<li>リバランスを有効にしていると、APIでシャードを別のノードに配置しても、リバランスされてしまうので注意</li>
<li>個人的な感想

<ul>
<li>オチがとてもおもしろかった.</li>
<li>Reroute APIって、制御できるのは良いけど、逆にいちいち制御するのはやってられないし、どーいう場面で使うのだろう、と思った.</li>
</ul>
</li>
</ul>


<h2>(LT)検索のダウンタイム0でバックアップからIndexをリストアする方法 @k_bigwheel 氏</h2>

<ul>
<li><a href="http://www.slideshare.net/kbigwheel/0index-39143333">資料</a></li>
<li>indexのスナップショットを取れるようになったけど、普通にやるとリストア対象のindexを一旦closeしないといけない. サービスの継続を考えると、ダウンタイム無しでやりたい、という話</li>
<li>予めクライアントからはalias経由でアクセスするようにしておく. aliasの切り替えはatomicにできるので、それを利用して、リストア完了後にスッパリ切り替える、という形にする</li>
<li>個人的な感想

<ul>
<li>リストアだけでなく、mappingを変えるためにindexしなおすとか、aliasを使うと便利な場面はありそう</li>
<li>しかし、自分の環境はfluentdで&#8221;name-YYYY.MM.DD&#8221;の形でindexを作っているので、この場合aliasはどうしたらいいんだろう</li>
</ul>
</li>
</ul>


<h2>全体所感</h2>

<ul>
<li>最近、Elasticsearchを真面目に使い始めてみたので、どのトークも大変参考になった. 特に、 @satully 氏の話は良かった</li>
<li>結構、みんなAWSなんだな</li>
<li>懇親会で、発表についてのもう少し詳しい話とか、他の人がどんな感じに使ってるとか聞けたので、そっちも良かった. しかも参加費無料. 素晴らしい.</li>
<li>主催の@johtaniさん、会場提供のリクルートテクノロジーズさんに感謝.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentdの障害時動作]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/06/04/how-fluentd-works-in-case-of-failures/"/>
    <updated>2014-06-04T23:12:23+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/06/04/how-fluentd-works-in-case-of-failures</id>
    <content type="html"><![CDATA[<p>Fluentdが障害の時にどのような動作をするのか調べてみたので、そのメモ. td-agent 1.1.17(fluentd v0.10.39)で確認したつもりだが、もしかしたらもう少し新しいので確認したケースもあるかも. BufferedOutputを中心に記載している.</p>

<h2>BufferdOutputの基本</h2>

<p>fluentdの特徴の一つとして、fluentd送信先で障害があり、メッセージが送れなかった場合は大抵(BufferedOutputを使っているプラグインであれば)fluentdでバッファリングし、一定時間後に再送してくれる.</p>

<p>このバッファリングのサイズは、BufferedOutputプラグインのbuffer_chunk_limit*buffer_queue_limitで決まる.</p>

<p>これらのデフォルト値は以下に解説付きでまとまっている. (良く参照させて頂いています)
<a href="http://d.hatena.ne.jp/tagomoris/20130123/1358929254">FluentdでバッファつきOutputPluginを使うときのデフォルト値</a></p>

<h2>何回くらいリトライするの？ リトライの間隔は？</h2>

<p>リトライの回数は、retry_limit(デフォルト 17)で指定された回数まで. 間隔は一定ではなく、段々延びていく. 具体的に間隔を計算してるのは、BufferedOutput#calc_retry_wait.</p>

<p>リトライ間隔は、以下のパラメータでコントロールすることができる</p>

<ul>
<li>max_retry_wait(デフォルト: nil = 上限なし)</li>
<li>retry_wait (デフォルト: 1.0)</li>
</ul>


<p>同じメソッドを使って、実際にどれくらいになるのかを計算させてみた. 以下で例えば、1=>2は、一度送信に失敗してから、2回目の送信を試みるまでという意味. 単位は秒. 全てデフォルト値だと、以下の様な感じ. 最大だと、33765秒=9時間22分になる.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>1=&gt;2 : 1.0799124443510373
</span><span class='line'>2=&gt;3 : 1.8141315928054327
</span><span class='line'>3=&gt;4 : 3.5115188260172046
</span><span class='line'>4=&gt;5 : 7.106397160810471
</span><span class='line'>5=&gt;6 : 14.175590112052593
</span><span class='line'>6=&gt;7 : 31.434005639868758
</span><span class='line'>7=&gt;8 : 68.4743252224448
</span><span class='line'>8=&gt;9 : 116.47949944913451
</span><span class='line'>9=&gt;10 : 279.97276701667636
</span><span class='line'>10=&gt;11 : 487.69976826480445
</span><span class='line'>11=&gt;12 : 909.7729519328531
</span><span class='line'>12=&gt;13 : 2125.0559803853725
</span><span class='line'>13=&gt;14 : 3717.0255349933364
</span><span class='line'>14=&gt;15 : 8658.913465429461
</span><span class='line'>15=&gt;16 : 18189.354025481873
</span><span class='line'>16=&gt;17 : 33765.98470398931
</span></code></pre></td></tr></table></div></figure>


<p>例えば、max_retry_wait=120とすると、以下のようになる. 何回リトライしても、リトライ間隔の上限はmax_retry_waitまでになる.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>1=&gt;2 : 1.0717022666140232
</span><span class='line'>2=&gt;3 : 1.9866738239982864
</span><span class='line'>3=&gt;4 : 3.9258714996769903
</span><span class='line'>4=&gt;5 : 7.002702902759963
</span><span class='line'>5=&gt;6 : 15.817343449261045
</span><span class='line'>6=&gt;7 : 34.49173945537066
</span><span class='line'>7=&gt;8 : 65.98469012616731
</span><span class='line'>8=&gt;9 : 120
</span><span class='line'>9=&gt;10 : 120
</span><span class='line'>10=&gt;11 : 120
</span><span class='line'>11=&gt;12 : 120
</span><span class='line'>12=&gt;13 : 120
</span><span class='line'>13=&gt;14 : 120
</span><span class='line'>14=&gt;15 : 120
</span><span class='line'>15=&gt;16 : 120
</span><span class='line'>16=&gt;17 : 120
</span></code></pre></td></tr></table></div></figure>


<p>retry_waitを半分の0.5にすると、全てのリトライ間隔が半分になる.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>1=&gt;2 : 0.46442639898905974
</span><span class='line'>2=&gt;3 : 0.9688421553729557
</span><span class='line'>3=&gt;4 : 2.2291735347851613
</span><span class='line'>4=&gt;5 : 3.545406346443683
</span><span class='line'>5=&gt;6 : 7.824124603156501
</span><span class='line'>6=&gt;7 : 17.564462446502926
</span><span class='line'>7=&gt;8 : 30.97024814321994
</span><span class='line'>8=&gt;9 : 71.84343582620227
</span><span class='line'>9=&gt;10 : 127.87010583643446
</span><span class='line'>10=&gt;11 : 286.751861977861
</span><span class='line'>11=&gt;12 : 551.32668884554
</span><span class='line'>12=&gt;13 : 1077.2785515357239
</span><span class='line'>13=&gt;14 : 2095.196745718026
</span><span class='line'>14=&gt;15 : 3995.080966184667
</span><span class='line'>15=&gt;16 : 9131.408473518048
</span><span class='line'>16=&gt;17 : 16810.484835714517
</span></code></pre></td></tr></table></div></figure>


<p>リトライの頻度を増やす(リトライ間隔を減らす)場合は、併せてretry_limitも変更しないと、早々にリトライアウトしてしまう、ということになるので注意.</p>

<h2>リトライ回数が超過したら？</h2>

<p>リトライ回数を超過した場合、secodaryディレクティブを指定しておけば、そちらに出力される. 通常は、ファイルに出力しておいて、後からリカバリに使う、というケースが多いと思う.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  &lt;secondary&gt;
</span><span class='line'>    type file
</span><span class='line'>    path /path/to/forward-failed
</span><span class='line'>  &lt;/secondary&gt;</span></code></pre></td></tr></table></div></figure>


<p>このようなケースでは、ログに以下のように出力される</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2014-06-22 07:06:40 +0900 [warn]: fluent/output.rb:352:rescue in try_flush: retry count exceededs limit. falling back to secondary output.
</span></code></pre></td></tr></table></div></figure>


<h2>キューが溢れたら？</h2>

<p>キュー(バッファ)が溢れると、fluentdのログに以下のようなメッセージが出る.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2014-05-25 11:30:23 +0900 [warn]: fluent/engine.rb:149:rescue in emit_stream: emit transaction failed  error_class=Fluent::BufferQueueLimitError error=#&lt;Fluent::BufferQueueLimitError: queue size exceeds limit&gt;
</span></code></pre></td></tr></table></div></figure>


<p>この場合、inputプラグインがEngine.emitを実行する際にExceptionが発生する. プラグインが、これをrescueしていない場合、inputプラグインは停止する. rescueしている場合はinputプラグインの実装次第だが、大抵Exceptionは無視されてemitしたデータは破棄される.
(既に溜めるためのキューがあふれているので、それしか無い)</p>

<h2>送信先が復活したら?</h2>

<p>再送中に送信先が復活し、再送に成功した場合は以下の様なメッセージが出力される.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2014-05-25 11:33:01 +0900 [warn]: fluent/output.rb:312:try_flush: retry succeeded. instance=70365422937420</span></code></pre></td></tr></table></div></figure>


<p>ここで、注意点として送信先が復活してもすぐに再送してくれるわけではない. これは、送信先とのハートビートを行っているout_forwardでも一緒. BufferedOutput#try_flushのコードを見ると分かるが、リトライ中で、まだ次のリトライ時刻に達していない場合は、送信は行わない.</p>

<p>なので、retryを繰り返して再送間隔が延びている場合は、次の再送タイミングになるまでキューが溜まり続ける(もしくは、既に溢れている場合は溢れ続ける)</p>

<h2>キューを強制的に送信することはできないの？</h2>

<p>リトライ中の場合以外であれば、fluentdのプロセスにSIGUSR1を送ることでキューが吐き出される. リトライ中の場合は、次のリトライタイミングまでは送信されない. 全てのキューを吐き出すには、プロセスを停止するしかない.</p>

<p>プロセス停止時の挙動は使用しているバッファプラグインによって異なるが</p>

<ul>
<li>buf_memoryの場合

<ul>
<li>プロセス停止時に全てのキューが吐き出される.</li>
</ul>
</li>
<li>buf_fileの場合

<ul>
<li>flush_at_shutdownがtrue(デフォルト false)の場合のみ、プロセス停止時に全てのキューが吐き出される.</li>
</ul>
</li>
</ul>


<p>長くなったのでここまで.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetを使っていて思ったことなどをまとめてみる]]></title>
    <link href="http://ogibayashi.github.io/blog/2014/02/26/about-puppet-1/"/>
    <updated>2014-02-26T22:45:06+09:00</updated>
    <id>http://ogibayashi.github.io/blog/2014/02/26/about-puppet-1</id>
    <content type="html"><![CDATA[<h2>この記事について</h2>

<p>puppetを初めて触ってから3,4年くらい経ったが、その間に思ったことなどをまとめてみる. なぜpuppetか、何に使っているか、使っていて思ったこと、課題など.</p>

<h2>利用状況を簡単に</h2>

<p>こんな環境で使ってます.</p>

<h3>puppetの使用環境</h3>

<p>CentOS 5 and 6で、puppetは2.7.21. 大体4つくらいの独立した(ネットワーク的に分断された)環境で、サーバ台数は合計百数十台. サーバ上で稼働する(した)ソフトウェアはHadoop, fluentd, MongoDB, Cassandra, MySQL, Munin等.</p>

<h3>何に使っているか</h3>

<p>上記ソフトウェアの環境は基本的にpuppetで構築している.が、puppetで完結できていることだけではないので、それは後述</p>

<h2>使っていて思ったこと</h2>

<p>今まで使っていて思ったことなどを書いてみる.</p>

<h3>puppetで何が良いか</h3>

<p>puppetだけではなく、chef等でも一緒だと思うけど、この手のソフトウェアを使わない場合だと、シェルスクリプトで頑張るか、VMのイメージをコピーするか、になると思う. それぞれに対して比較すると</p>

<ul>
<li>シェルスクリプト等でやる場合

<ul>
<li>色々全部自分で書かないといけないのでしんどい. 単一の環境、初回構築なら良いけど、ちょっと違う環境を作るとか、一旦作った環境に変更を加えるとか. 規模が大きくなってくると、モジュール化したり、過去に作ったものを再利用したくなるけど、その点でもつらい.</li>
</ul>
</li>
<li>VMのイメージコピーの場合

<ul>
<li>既に構築済の環境に対する変更をどう適用するか、環境の変更履歴をどう管理するか、というところが課題.</li>
</ul>
</li>
</ul>


<p>puppetは、&#8221;このサーバはこうあるべき&#8221;と定義すれば、前の状態がどうであってもその状態にしてくれるので、いちいちチェックして、期待と違ったら処理をして、みたいなことを書かなくて済む. また、クラス、モジュール、等再利用性を促すような言語の機能もあるので、うまく書けば既存のコードを流用しつつ、新しい要件に対応するようにマニフェストを変更していくようなこともやりやすい.</p>

<p>ただ、実はそれだけではなくてInfrastructure as Code, サーバ環境がコードで表現できるようになり、アプリケーションのコードと同じように変更管理、レビュー、テスト、デプロイができるようになるのが大きいと思う. このあたりは<a href="http://d.hatena.ne.jp/naoya/20131215/1387090668">naoyaさんの記事</a>に詳しく書かれている.</p>

<h3>puppetの使いどころ</h3>

<p>サーバ構築のうち、何をpuppetでやるべきか？サーバ構築はBootstrapping, Configuration, Orchestrationの3つのレイヤに分けて考えられることが多いが、この中だとConfigurationの部分をpuppetでやることが有効</p>

<p>つまり、</p>

<ul>
<li>Bootstrappingに相当する部分、OSインストール、ネットワーク設定、puppet自体のインストール、はやらない(やれない)</li>
<li>Orchestrationに相当する部分、複数台の協調操作が必要な操作もやらない. 今はここはfabric(局所的にserf)でやっている.</li>
<li>その他、puppetが動作可能になった後のconfigurationで、単一サーバ内で完結するようなものは全てpuppetで行う.</li>
</ul>


<p>という感じにしている.</p>

<h3>マニフェストのいい感じの書き方</h3>

<p>いい感じ、というのは読みやすく、再利用しやすい、ということ. これは、使い始めてからずっと試行錯誤しているところ. そのための要素としては、以下があると思う.</p>

<ol>
<li>モジュールの書き方</li>
<li>モジュールを組み合わせて、実際のサーバに適用するマニフェストにする部分をどう書くか</li>
<li>環境依存する部分をどのように切り出すか</li>
</ol>


<p>まず、1について. モジュールはライブラリのように環境が変わっても再利用可能なものであるべき. どのような書き方が良いか、というのは<a href="http://docs.puppetlabs.com/guides/module_guides/bgtm.html">このドキュメント</a>に書かれている. puppetlabs公式のntpモジュールが、お手本としては良いらしい.</p>

<p>2については、以下で紹介されている、RoleとProfileという考え方を導入するのが良い.</p>

<ul>
<li><a href="http://www.slideshare.net/PuppetLabs/roles-talk">http://www.slideshare.net/PuppetLabs/roles-talk</a></li>
<li><a href="http://www.craigdunn.org/2012/05/239/">http://www.craigdunn.org/2012/05/239/</a></li>
</ul>


<p>moduleを複数まとめてprofileが構成され、さらに複数profileをまとめてroleが構成される. node(=物理ホスト)は、一つのroleに紐付けられる、という形になっている. 例えば、<code>profile::webserver</code>にはhttpdとphpが必要で、<code>role::www::dev</code>は、<code>profile::webserver</code>と<code>profile::database</code>が含まれる、みたいな形に書く. ただ、自分はまだroleの必要性がしっくりきてないので、profileとroleを分けていない.</p>

<p>3については、hieraやENCを使ってあるサーバに適用するクラス(role/profile)や、そのパラメータをマニフェストの外に切り出す、というのが定番らしい. ただ、自分はまだこれらは導入していなくて、以下のように変数をまとめたクラスを作って、それを呼び出すときの引数で環境を切り替える、という風にしている. 今後はhiera or ENCに移行していきたい.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class base_env($envname="") {
</span><span class='line'>  case $envname {
</span><span class='line'>    "testenv" :{
</span><span class='line'>      $reposrv = "192.168.1.1"
</span><span class='line'>      $repourl = "http://$reposrv/Lang/Ruby/"
</span><span class='line'>    }
</span><span class='line'>    default: {
</span><span class='line'>      $masternode="192.168.1.2"
</span><span class='line'>      $reposrv = "example.deploy.local"
</span><span class='line'>      $repourl = "http://$reposrv/Lang/Ruby/"
</span><span class='line'>      $gfurl="http://$masternode:5125"
</span><span class='line'>      $munin_node=$masternode
</span><span class='line'>      $serf_join = ['192.168.1.1','192.168.1.2']
</span><span class='line'>      $munin_allow='^192\.168\..*$'
</span><span class='line'>
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::base($envname="") {
</span><span class='line'>  class{"base_env":
</span><span class='line'>    envname =&gt; $envname
</span><span class='line'>  }
</span><span class='line'>  ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>node /hadooptest\.hadoop.local/ {
</span><span class='line'>   class{"profile::base":
</span><span class='line'>     envname =&gt; "testenv"
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h3>puppetmasterについて</h3>

<p>つい最近まではpuppetmasterを使っていた. ただ、以下の問題があった.</p>

<ul>
<li>新しくサーバを構築するときにpuppetmasterが無ければ立てる必要がある</li>
<li>証明書が面倒. 自動署名にはしてるけど、同じホスト名でサーバの再構築することもそれなりにあったので、その度に証明書のクリアが必要. クリアしてなくてうまく同期できない、というのも良くあった.</li>
</ul>


<p>なので、最近はgitリポジトリにmanifestを配置して、各サーバでgit clone. という風にしている. マニフェストを更新した時は、fabricを使って並列にgit pull &amp; puppet applyする. 証明書の問題から開放されたし、サーバ台数が増えてもgitリポジトリを複数にすればスケールするし、gitが無くてもmanifestだけコピーすれば環境作れるし、でとても楽になった.</p>

<h2>今後の課題</h2>

<p>今はできていないので、これから取り組みたいこと.</p>

<h3>テスト</h3>

<p>上記の通り、puppet化、というかコード化するメリットとしてCI的なものは外せないと思うのだけど、まだできていない.
幸い<a href="http://blog.tmtk.net/2013/09/28/docker-jenkins-serverspec-puppet.ja.html">先人の事例</a>があるので、こちらを真似しながら環境はできた. ただ、まだ実験的な段階で、プロセスとして固まってない. Dockerだけでなく実機の環境もあるので、Dockerでテストして、通ったものは即検証環境に自動的にデプロイして、みたいな形にしたい.</p>

<h3>外部モジュール(Puppet Forge)の利用</h3>

<p>puppetを始めた当初は、公開されているモジュールがあると言っても今一つやりたいことにフィットしなくて、全て自分で書いていたのだけど、最近は公開されているものを有効活用した方が良い気がしてきた. 実際serfとかsensuとかのモジュールを使ってみたが、全然変更の必要が無く使えたので、これからは外部のものも使っていきたい. ただ、自分のいる環境はInternetにつながらないので<code>puppet module</code>コマンドは使えず、どうやって配布するかを考えないといけない. (自前リポジトリとか立てられるのかな&hellip;)</p>

<h2>最後に</h2>

<p>最近Infrastructure as Codeという言葉も良く聞かれるようになったし、自分も今までpuppetを使ってて思ったことを一度まとめてみようと思って書いてみた. しかし、puppetってやっぱり日本語の記事が少ない. 入門的な記事はあるのだけど、どう使ってるとか、何に困ったとか、どう工夫してるとかの情報がもっとあると良いなぁ. Qiitaでそれぞれのタグを見てみたら、Chefの投稿が242に対して、Puppetは11でした&hellip;</p>
]]></content>
  </entry>
  
</feed>
